{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lovely_tensors.patch import monkey_patch\n",
    "\n",
    "monkey_patch()\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the tiny stories dataset\n",
    "\n",
    "# TS_PATH = \"./ts/\"\n",
    "# TS_PATH = Path(TS_PATH)\n",
    "\n",
    "\n",
    "# gpt35_stories = []\n",
    "# gpt4_stories = []\n",
    "\n",
    "import unidecode\n",
    "\n",
    "# for file in tqdm(list(sorted(os.listdir(TS_PATH)))):\n",
    "#     if file.endswith(\".json\"):\n",
    "#         with open(TS_PATH / file, \"r\") as f:\n",
    "#             data = json.load(f)\n",
    "#             for d in data:\n",
    "#                 story = d[\"story\"]\n",
    "#                 if not all(ord(c) < 128 for c in story):\n",
    "#                     story = unidecode.unidecode(story)\n",
    "\n",
    "#                 if d[\"source\"] == \"GPT-3.5\":\n",
    "#                     gpt35_stories.append(story)\n",
    "#                 elif d[\"source\"] == \"GPT-4\":\n",
    "#                     gpt4_stories.append(story)\n",
    "\n",
    "# with open(\"gpt35_stories.txt\", \"w\") as f:\n",
    "#     f.write(\"\\n\".join(gpt35_stories))\n",
    "\n",
    "# with open(\"gpt4_stories.txt\", \"w\") as f:\n",
    "#     f.write(\"\\n\".join(gpt4_stories))\n",
    "\n",
    "with open(\"gpt35_stories.txt\", \"r\") as f:\n",
    "    gpt35_stories = f.readlines()\n",
    "\n",
    "with open(\"gpt4_stories.txt\", \"r\") as f:\n",
    "    gpt4_stories = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = \"\\n\".join(gpt35_stories + gpt4_stories)\n",
    "data = \"\\n\".join(gpt35_stories[:100_000])\n",
    "\n",
    "del gpt35_stories\n",
    "del gpt4_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
    "\n",
    "\n",
    "def decode(l):\n",
    "    return \"\".join(\n",
    "        [itos[i] for i in l]\n",
    "    )  # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n !\"$\\'()+,-.0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz',\n",
       " 76)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(chars), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_data = encode(data)\n",
    "train_data = data[: int(len(data)) - 200_000]\n",
    "val_data = data[int(len(data)) - 200_000 :]\n",
    "del data\n",
    "\n",
    "# train_data = torch.tensor(data)\n",
    "# val_data = torch.tensor(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(data, ctx):\n",
    "    # i = random.randint(0, len(data) - ctx - 1)\n",
    "    i = 0\n",
    "    while i + ctx < len(data):\n",
    "        src = data[i : i + ctx]\n",
    "        dst = data[i + 1 : i + ctx + 1]\n",
    "        yield torch.tensor(encode(src)), torch.tensor(encode(dst))\n",
    "        i += ctx\n",
    "\n",
    "\n",
    "def get_epoch(data, ctx_len, batch_size, shuffle=True):\n",
    "    \"\"\"Yields a tuple of tensors of shape (batch_size, ctx).\n",
    "    X, shape=B C\n",
    "    y, shape=B C\n",
    "    \"\"\"\n",
    "\n",
    "    items = get_item(data, ctx_len)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            X, y = zip(*[next(items) for _ in range(batch_size)])\n",
    "            yield torch.stack(X), torch.stack(y)\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor[2, 5] i64 n=10 x∈[1, 70] μ=48.200 σ=25.685 [[63, 52, 54, 1, 70], [67, 61, 1, 63, 50]],\n",
       " tensor[2, 5] i64 n=10 x∈[1, 70] μ=47.900 σ=25.467 [[52, 54, 1, 70, 65], [61, 1, 63, 50, 62]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_random_item(data, ctx):\n",
    "    i = random.randint(0, len(data) - ctx - 1)\n",
    "\n",
    "    src = data[i : i + ctx]\n",
    "    dst = data[i + 1 : i + ctx + 1]\n",
    "\n",
    "    return torch.tensor(encode(src)), torch.tensor(encode(dst))\n",
    "\n",
    "\n",
    "def get_batch(data, ctx_len, batch_size, shuffle=True):\n",
    "    \"\"\"Yields a tuple of tensors of shape (batch_size, ctx).\n",
    "    X, shape=B C\n",
    "    y, shape=B C\n",
    "    \"\"\"\n",
    "\n",
    "    batch = [get_random_item(data, ctx_len) for _ in range(batch_size)]\n",
    "    X, y = zip(*batch)\n",
    "\n",
    "    return torch.stack(X), torch.stack(y)\n",
    "\n",
    "\n",
    "get_batch(train_data[:100], ctx_len=5, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTX_LEN = 12\n",
    "EMBEDDING_DIM = 128\n",
    "BATCH_SIZE = 4096\n",
    "\n",
    "X, y = get_batch(train_data, ctx_len=CTX_LEN, batch_size=BATCH_SIZE, shuffle=True)\n",
    "X = X.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3] + [4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.zeros((128, EMBEDDING_DIM))\n",
    "M\n",
    "\n",
    "\n",
    "for pos in range(M.shape[0]):\n",
    "    for i in range(M.shape[1] // 2):\n",
    "        M[pos, 2 * i] = torch.sin(torch.tensor(pos / 10000 ** (i / M.shape[1])))\n",
    "        M[pos, 2 * i + 1] = torch.cos(torch.tensor(pos / 10000 ** ((i) / M.shape[1])))\n",
    "\n",
    "# M.chans(scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[4096, 76] n=311296 (1.2Mb) x∈[-1.531, 1.341] μ=-0.041 σ=0.388 cuda:0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def attention_block(params, input_ids, vocab_size):\n",
    "import math\n",
    "\n",
    "\n",
    "def make_params(embedding_dim, ctx_len, vocab_size, layers, device):\n",
    "    model_params = {\n",
    "        \"embedding\": torch.randn((vocab_size, embedding_dim), device=device),\n",
    "        \"pos_enc\": torch.randn((embedding_dim, ctx_len), device=device),\n",
    "        \"blocks\": [],\n",
    "        \"w_ln_f\": torch.ones((embedding_dim), device=device),\n",
    "        \"b_ln_f\": torch.zeros((embedding_dim,), device=device),\n",
    "        \"decoding\": torch.rand((vocab_size, embedding_dim), device=device)\n",
    "        / math.sqrt(vocab_size),\n",
    "    }\n",
    "\n",
    "    for _ in range(layers):\n",
    "        block = {\n",
    "            \"w_ln1\": torch.ones((embedding_dim), device=device),\n",
    "            \"b_ln1\": torch.zeros((embedding_dim,), device=device),\n",
    "            \"w_attn_k\": torch.randn((embedding_dim, embedding_dim), device=device),\n",
    "            \"w_attn_q\": torch.randn((embedding_dim, embedding_dim), device=device),\n",
    "            \"w_attn_v\": torch.randn((embedding_dim, embedding_dim), device=device),\n",
    "            \"w_fc_up\": torch.randn((embedding_dim * 4, embedding_dim), device=device),\n",
    "            \"b_fc_up\": torch.randn((embedding_dim * 4,), device=device),\n",
    "            \"w_fc_down\": torch.randn((embedding_dim, embedding_dim * 4), device=device),\n",
    "            \"b_fc_down\": torch.randn((embedding_dim,), device=device),\n",
    "            \"w_ln2\": torch.ones((embedding_dim), device=device),\n",
    "            \"b_ln2\": torch.zeros((embedding_dim,), device=device),\n",
    "        }\n",
    "        model_params[\"blocks\"].append(block)\n",
    "\n",
    "    return model_params\n",
    "\n",
    "\n",
    "def init_params(params):\n",
    "    M = params[\"pos_enc\"]\n",
    "    for pos in range(M.shape[0]):\n",
    "        for i in range(M.shape[1] // 2):\n",
    "            M[M.shape[0] - 1 - pos, 2 * i] = torch.sin(\n",
    "                torch.tensor(pos / 10000 ** (i / M.shape[1]))\n",
    "            )\n",
    "            M[M.shape[0] - 1 - pos, 2 * i + 1] = torch.cos(\n",
    "                torch.tensor(pos / 10000 ** ((i) / M.shape[1]))\n",
    "            )\n",
    "\n",
    "\n",
    "model_params = make_params(EMBEDDING_DIM, CTX_LEN, len(chars), 2, device)\n",
    "init_params(model_params)\n",
    "\n",
    "\n",
    "def transformer_block(params, hidden_states):\n",
    "    res1 = hidden_states\n",
    "    # print(f\"{hidden_states=}\")\n",
    "\n",
    "    ln1 = torch.nn.functional.layer_norm(\n",
    "        input=hidden_states,\n",
    "        weight=params[\"w_ln1\"],\n",
    "        bias=params[\"w_ln1\"],\n",
    "        normalized_shape=(hidden_states.shape[-1],),\n",
    "    )\n",
    "\n",
    "    # print(f\"{ln1=}\")\n",
    "    # print(f\"{params['w_attn_k'].T=}\")\n",
    "\n",
    "    attn_k = ln1 @ params[\"w_attn_k\"].T\n",
    "    attn_q = ln1 @ params[\"w_attn_q\"].T\n",
    "    attn_v = ln1 @ params[\"w_attn_v\"].T\n",
    "\n",
    "    # print(f\"{attn_k=}\")\n",
    "    # print(f\"{attn_q=}\")\n",
    "\n",
    "    n_embed = hidden_states.shape[-1]\n",
    "    attn = (attn_q @ attn_k.transpose(-1, -2)) / math.sqrt(n_embed)\n",
    "\n",
    "    attn = torch.nn.functional.softmax(attn, dim=-1)\n",
    "\n",
    "    out = attn @ attn_v + res1\n",
    "\n",
    "    res2 = out\n",
    "\n",
    "    ln2 = torch.nn.functional.layer_norm(\n",
    "        input=out,\n",
    "        weight=params[\"w_ln2\"],\n",
    "        bias=params[\"b_ln2\"],\n",
    "        normalized_shape=(hidden_states.shape[-1],),\n",
    "    )\n",
    "\n",
    "    fc_up = ln2 @ params[\"w_fc_up\"].T + params[\"b_fc_up\"]\n",
    "    fc_up = torch.nn.functional.gelu(fc_up)\n",
    "\n",
    "    fc_down = fc_up @ params[\"w_fc_down\"].T + params[\"b_fc_down\"]\n",
    "\n",
    "    return fc_down + res2\n",
    "\n",
    "\n",
    "def model(params, input_ids, vocab_size):\n",
    "    input_ids = input_ids.long()\n",
    "\n",
    "    embeddings = params[\"embedding\"][input_ids]  # N, CTX_LEN, EMBEDDING_DIM\n",
    "    pos_enc = params[\"pos_enc\"].T[: input_ids.shape[1]]\n",
    "\n",
    "    hidden_states = embeddings + pos_enc\n",
    "    # print(embeddings)\n",
    "\n",
    "    for block in params[\"blocks\"]:\n",
    "        hidden_states = transformer_block(block, hidden_states)\n",
    "\n",
    "    ln_f = torch.nn.functional.layer_norm(\n",
    "        input=hidden_states,\n",
    "        weight=params[\"w_ln_f\"],\n",
    "        bias=params[\"b_ln_f\"],\n",
    "        normalized_shape=(hidden_states.shape[-1],),\n",
    "    )\n",
    "\n",
    "    return ln_f[:, -1, :] @ params[\"decoding\"].T\n",
    "\n",
    "\n",
    "res = model(model_params, X, len(chars))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"872.39952pt\" height=\"152.406273pt\" viewBox=\"0 0 872.39952 152.406273\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 152.406273 \n",
       "L 872.39952 152.406273 \n",
       "L 872.39952 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 7.2 128.528148 \n",
       "L 865.19952 128.528148 \n",
       "L 865.19952 20.214138 \n",
       "L 7.2 20.214138 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m8f1de1206a\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"23.693647\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −1.00 -->\n",
       "      <g transform=\"translate(8.370991 143.126585) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"126.778941\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −0.75 -->\n",
       "      <g transform=\"translate(111.456285 143.126585) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
       "L 3525 4666 \n",
       "L 3525 4397 \n",
       "L 1831 0 \n",
       "L 1172 0 \n",
       "L 2766 4134 \n",
       "L 525 4134 \n",
       "L 525 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"229.864235\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- −0.50 -->\n",
       "      <g transform=\"translate(214.541579 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"332.949529\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- −0.25 -->\n",
       "      <g transform=\"translate(317.626873 143.126585) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"179.199219\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"436.034824\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 0.00 -->\n",
       "      <g transform=\"translate(424.902011 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"539.120118\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 0.25 -->\n",
       "      <g transform=\"translate(527.987305 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"642.205412\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.50 -->\n",
       "      <g transform=\"translate(631.072599 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"745.290706\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.75 -->\n",
       "      <g transform=\"translate(734.157893 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8f1de1206a\" x=\"848.376\" y=\"128.528148\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1.00 -->\n",
       "      <g transform=\"translate(837.243187 143.126585) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\"/>\n",
       "   <g id=\"line2d_10\">\n",
       "    <path d=\"M 137.398796 128.528148 \n",
       "L 137.398796 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_11\">\n",
       "    <path d=\"M 299.491326 128.528148 \n",
       "L 299.491326 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path d=\"M 461.583856 128.528148 \n",
       "L 461.583856 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path d=\"M 623.676387 128.528148 \n",
       "L 623.676387 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 785.768917 128.528148 \n",
       "L 785.768917 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #000000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 110.7803 128.528148 \n",
       "L 110.7803 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 794.158687 128.528148 \n",
       "L 794.158687 20.214138 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #ff0000; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 7.2 128.528148 \n",
       "L 7.2 20.214138 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 865.19952 128.528148 \n",
       "L 865.19952 20.214138 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 7.2 128.528148 \n",
       "L 865.19952 128.528148 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 7.2 20.214138 \n",
       "L 865.19952 20.214138 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_10\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 109.7803 104.10708 \n",
       "L 109.7803 44.635205 \n",
       "Q 109.7803 44.635205 109.7803 44.635205 \n",
       "L 100.102175 44.635205 \n",
       "Q 100.102175 44.635205 100.102175 44.635205 \n",
       "L 100.102175 104.10708 \n",
       "Q 100.102175 104.10708 100.102175 104.10708 \n",
       "L 109.7803 104.10708 \n",
       "Q 109.7803 104.10708 109.7803 104.10708 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- min=-0.789 -->\n",
       "    <g transform=\"translate(107.700612 104.10708) rotate(-90) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \n",
       "L 4684 2906 \n",
       "L 4684 2381 \n",
       "L 678 2381 \n",
       "L 678 2906 \n",
       "z\n",
       "M 678 1631 \n",
       "L 4684 1631 \n",
       "L 4684 1100 \n",
       "L 678 1100 \n",
       "L 678 1631 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-2d\" d=\"M 313 2009 \n",
       "L 1997 2009 \n",
       "L 1997 1497 \n",
       "L 313 1497 \n",
       "L 313 2009 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-39\" d=\"M 703 97 \n",
       "L 703 672 \n",
       "Q 941 559 1184 500 \n",
       "Q 1428 441 1663 441 \n",
       "Q 2288 441 2617 861 \n",
       "Q 2947 1281 2994 2138 \n",
       "Q 2813 1869 2534 1725 \n",
       "Q 2256 1581 1919 1581 \n",
       "Q 1219 1581 811 2004 \n",
       "Q 403 2428 403 3163 \n",
       "Q 403 3881 828 4315 \n",
       "Q 1253 4750 1959 4750 \n",
       "Q 2769 4750 3195 4129 \n",
       "Q 3622 3509 3622 2328 \n",
       "Q 3622 1225 3098 567 \n",
       "Q 2575 -91 1691 -91 \n",
       "Q 1453 -91 1209 -44 \n",
       "Q 966 3 703 97 \n",
       "z\n",
       "M 1959 2075 \n",
       "Q 2384 2075 2632 2365 \n",
       "Q 2881 2656 2881 3163 \n",
       "Q 2881 3666 2632 3958 \n",
       "Q 2384 4250 1959 4250 \n",
       "Q 1534 4250 1286 3958 \n",
       "Q 1038 3666 1038 3163 \n",
       "Q 1038 2656 1286 2365 \n",
       "Q 1534 2075 1959 2075 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"125.195312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3d\" x=\"188.574219\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"272.363281\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"308.447266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"372.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-37\" x=\"403.857422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"467.480469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"531.103516\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_11\">\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 805.836812 103.768799 \n",
       "L 805.836812 44.973487 \n",
       "Q 805.836812 44.973487 805.836812 44.973487 \n",
       "L 796.158687 44.973487 \n",
       "Q 796.158687 44.973487 796.158687 44.973487 \n",
       "L 796.158687 103.768799 \n",
       "Q 796.158687 103.768799 796.158687 103.768799 \n",
       "L 805.836812 103.768799 \n",
       "Q 805.836812 103.768799 805.836812 103.768799 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- max=0.869 -->\n",
       "    <g transform=\"translate(803.757125 103.768799) rotate(-90) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-78\" d=\"M 3513 3500 \n",
       "L 2247 1797 \n",
       "L 3578 0 \n",
       "L 2900 0 \n",
       "L 1881 1375 \n",
       "L 863 0 \n",
       "L 184 0 \n",
       "L 1544 1831 \n",
       "L 300 3500 \n",
       "L 978 3500 \n",
       "L 1906 2253 \n",
       "L 2834 3500 \n",
       "L 3513 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"97.412109\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-78\" x=\"158.691406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3d\" x=\"217.871094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"301.660156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"365.283203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"397.070312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-36\" x=\"460.693359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"524.316406\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_12\">\n",
       "    <!-- tensor[76] x∈[-0.789, 0.869] μ=0.062 σ=0.393 cuda:0 -->\n",
       "    <g transform=\"translate(7.2 14.798437) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \n",
       "L 1875 4863 \n",
       "L 1875 4416 \n",
       "L 1125 4416 \n",
       "L 1125 -397 \n",
       "L 1875 -397 \n",
       "L 1875 -844 \n",
       "L 550 -844 \n",
       "L 550 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-5d\" d=\"M 1947 4863 \n",
       "L 1947 -844 \n",
       "L 622 -844 \n",
       "L 622 -397 \n",
       "L 1369 -397 \n",
       "L 1369 4416 \n",
       "L 622 4416 \n",
       "L 622 4863 \n",
       "L 1947 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-2208\" d=\"M 1072 1959 \n",
       "Q 1094 1728 1291 1353 \n",
       "Q 1522 919 1959 675 \n",
       "Q 2388 438 2850 434 \n",
       "L 5028 434 \n",
       "L 5028 -63 \n",
       "L 2850 -63 \n",
       "Q 2250 -63 1695 246 \n",
       "Q 1141 556 844 1106 \n",
       "Q 547 1656 547 2241 \n",
       "Q 547 2819 844 3369 \n",
       "Q 1141 3919 1695 4231 \n",
       "Q 2250 4544 2850 4544 \n",
       "L 5028 4544 \n",
       "L 5028 4047 \n",
       "L 2850 4047 \n",
       "Q 2388 4044 1959 3803 \n",
       "Q 1525 3556 1291 3125 \n",
       "Q 1091 2750 1063 2459 \n",
       "L 5028 2459 \n",
       "L 5028 1959 \n",
       "L 1072 1959 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-2c\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 256 \n",
       "L 897 -744 \n",
       "L 494 -744 \n",
       "L 750 256 \n",
       "L 750 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3bc\" d=\"M 544 -1331 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1325 \n",
       "Q 1119 872 1334 640 \n",
       "Q 1550 409 1972 409 \n",
       "Q 2434 409 2667 671 \n",
       "Q 2900 934 2900 1459 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 806 \n",
       "Q 3475 619 3529 530 \n",
       "Q 3584 441 3700 441 \n",
       "Q 3728 441 3778 458 \n",
       "Q 3828 475 3916 513 \n",
       "L 3916 50 \n",
       "Q 3788 -22 3673 -56 \n",
       "Q 3559 -91 3450 -91 \n",
       "Q 3234 -91 3106 31 \n",
       "Q 2978 153 2931 403 \n",
       "Q 2775 156 2548 32 \n",
       "Q 2322 -91 2016 -91 \n",
       "Q 1697 -91 1473 31 \n",
       "Q 1250 153 1119 397 \n",
       "L 1119 -1331 \n",
       "L 544 -1331 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3c3\" d=\"M 1959 3044 \n",
       "Q 1484 3044 1228 2700 \n",
       "Q 959 2341 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2319 2688 2700 \n",
       "Q 2441 3044 1959 3044 \n",
       "z\n",
       "M 1959 3500 \n",
       "L 3869 3500 \n",
       "L 3869 2925 \n",
       "L 3225 2925 \n",
       "Q 3566 2438 3566 1747 \n",
       "Q 3566 888 3138 400 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 781 400 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2613 781 3097 \n",
       "Q 1134 3500 1959 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
       "L 2906 4863 \n",
       "L 3481 4863 \n",
       "L 3481 0 \n",
       "L 2906 0 \n",
       "L 2906 525 \n",
       "Q 2725 213 2448 61 \n",
       "Q 2172 -91 1784 -91 \n",
       "Q 1150 -91 751 415 \n",
       "Q 353 922 353 1747 \n",
       "Q 353 2572 751 3078 \n",
       "Q 1150 3584 1784 3584 \n",
       "Q 2172 3584 2448 3432 \n",
       "Q 2725 3281 2906 2969 \n",
       "z\n",
       "M 947 1747 \n",
       "Q 947 1113 1208 752 \n",
       "Q 1469 391 1925 391 \n",
       "Q 2381 391 2643 752 \n",
       "Q 2906 1113 2906 1747 \n",
       "Q 2906 2381 2643 2742 \n",
       "Q 2381 3103 1925 3103 \n",
       "Q 1469 3103 1208 2742 \n",
       "Q 947 2381 947 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 0 \n",
       "L 750 0 \n",
       "L 750 794 \n",
       "z\n",
       "M 750 3309 \n",
       "L 1409 3309 \n",
       "L 1409 2516 \n",
       "L 750 2516 \n",
       "L 750 3309 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-74\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"39.208984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"100.732422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-73\" x=\"164.111328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"216.210938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"277.392578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-5b\" x=\"318.505859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-37\" x=\"357.519531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-36\" x=\"421.142578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-5d\" x=\"484.765625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"523.779297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-78\" x=\"555.566406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2208\" x=\"614.746094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-5b\" x=\"701.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2d\" x=\"740.869141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"776.953125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"840.576172\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-37\" x=\"872.363281\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"935.986328\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"999.609375\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2c\" x=\"1063.232422\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1095.019531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"1126.806641\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"1190.429688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-38\" x=\"1222.216797\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-36\" x=\"1285.839844\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"1349.462891\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-5d\" x=\"1413.085938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1452.099609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3bc\" x=\"1483.886719\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3d\" x=\"1547.509766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"1631.298828\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"1694.921875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"1726.708984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-36\" x=\"1790.332031\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"1853.955078\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"1917.578125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3c3\" x=\"1949.365234\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3d\" x=\"2012.744141\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"2096.533203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-2e\" x=\"2160.15625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-33\" x=\"2191.943359\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-39\" x=\"2255.566406\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-33\" x=\"2319.189453\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"2382.8125\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-63\" x=\"2414.599609\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"2469.580078\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-64\" x=\"2532.958984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"2596.435547\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3a\" x=\"2657.714844\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-30\" x=\"2691.40625\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 110.7803 128.528148 \n",
       "L 179.118143 128.528148 \n",
       "L 179.118143 110.216398 \n",
       "L 110.7803 110.216398 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 179.118143 128.528148 \n",
       "L 247.455975 128.528148 \n",
       "L 247.455975 110.216395 \n",
       "L 179.118143 110.216395 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 247.455975 128.528148 \n",
       "L 315.793818 128.528148 \n",
       "L 315.793818 85.800731 \n",
       "L 247.455975 85.800731 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 315.793818 128.528148 \n",
       "L 384.131656 128.528148 \n",
       "L 384.131656 49.177225 \n",
       "L 315.793818 49.177225 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 384.131656 128.528148 \n",
       "L 452.469494 128.528148 \n",
       "L 452.469494 55.281142 \n",
       "L 384.131656 55.281142 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 452.469494 128.528148 \n",
       "L 520.807331 128.528148 \n",
       "L 520.807331 67.488976 \n",
       "L 452.469494 67.488976 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 520.807331 128.528148 \n",
       "L 589.145169 128.528148 \n",
       "L 589.145169 79.69681 \n",
       "L 520.807331 79.69681 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 589.145169 128.528148 \n",
       "L 657.483 128.528148 \n",
       "L 657.483 61.385053 \n",
       "L 589.145169 61.385053 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 657.483 128.528148 \n",
       "L 725.820844 128.528148 \n",
       "L 725.820844 98.008565 \n",
       "L 657.483 98.008565 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 725.820844 128.528148 \n",
       "L 794.158687 128.528148 \n",
       "L 794.158687 104.112481 \n",
       "L 725.820844 104.112481 \n",
       "z\n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: #00bfff\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path d=\"M 7.2 126.994036 \n",
       "L 15.866662 126.74852 \n",
       "L 24.533324 126.469606 \n",
       "L 33.199985 126.153777 \n",
       "L 41.866647 125.79731 \n",
       "L 50.533309 125.396292 \n",
       "L 59.199971 124.946638 \n",
       "L 67.866633 124.444118 \n",
       "L 76.533295 123.884384 \n",
       "L 85.199956 123.263009 \n",
       "L 93.866618 122.57553 \n",
       "L 102.53328 121.817498 \n",
       "L 111.199942 120.98453 \n",
       "L 119.866604 120.072378 \n",
       "L 128.533265 119.076987 \n",
       "L 137.199927 117.994578 \n",
       "L 145.866589 116.821718 \n",
       "L 154.533251 115.555405 \n",
       "L 163.199913 114.193151 \n",
       "L 171.866575 112.733067 \n",
       "L 180.533236 111.173949 \n",
       "L 189.199898 109.515362 \n",
       "L 197.86656 107.757723 \n",
       "L 206.533222 105.902374 \n",
       "L 215.199884 103.95165 \n",
       "L 223.866545 101.908949 \n",
       "L 232.533207 99.778771 \n",
       "L 241.199869 97.566766 \n",
       "L 249.866531 95.279752 \n",
       "L 258.533193 92.925728 \n",
       "L 267.199855 90.513865 \n",
       "L 275.866516 88.054483 \n",
       "L 284.533178 85.559002 \n",
       "L 293.19984 83.039884 \n",
       "L 301.866502 80.510546 \n",
       "L 310.533164 77.985264 \n",
       "L 319.199825 75.479046 \n",
       "L 327.866487 73.007503 \n",
       "L 336.533149 70.586689 \n",
       "L 345.199811 68.232938 \n",
       "L 353.866473 65.962687 \n",
       "L 362.533135 63.792285 \n",
       "L 371.199796 61.737802 \n",
       "L 379.866458 59.814833 \n",
       "L 388.53312 58.038301 \n",
       "L 397.199782 56.422267 \n",
       "L 405.866444 54.979742 \n",
       "L 414.533105 53.722516 \n",
       "L 423.199767 52.660995 \n",
       "L 431.866429 51.80406 \n",
       "L 440.533091 51.158943 \n",
       "L 449.199753 50.731123 \n",
       "L 457.866415 50.52425 \n",
       "L 466.533076 50.540095 \n",
       "L 475.199738 50.778523 \n",
       "L 483.8664 51.237493 \n",
       "L 492.533062 51.913091 \n",
       "L 501.199724 52.799584 \n",
       "L 509.866385 53.889498 \n",
       "L 518.533047 55.173729 \n",
       "L 527.199709 56.641663 \n",
       "L 535.866371 58.281328 \n",
       "L 544.533033 60.079551 \n",
       "L 553.199695 62.02214 \n",
       "L 561.866356 64.094062 \n",
       "L 570.533018 66.279644 \n",
       "L 579.19968 68.562764 \n",
       "L 587.866342 70.927048 \n",
       "L 596.533004 73.356063 \n",
       "L 605.199665 75.833505 \n",
       "L 613.866327 78.343371 \n",
       "L 622.532989 80.87013 \n",
       "L 631.199651 83.398866 \n",
       "L 639.866313 85.915422 \n",
       "L 648.532975 88.406508 \n",
       "L 657.199636 90.859808 \n",
       "L 665.866298 93.264053 \n",
       "L 674.53296 95.609085 \n",
       "L 683.199622 97.885898 \n",
       "L 691.866284 100.086662 \n",
       "L 700.532945 102.204724 \n",
       "L 709.199607 104.234601 \n",
       "L 717.866269 106.171951 \n",
       "L 726.532931 108.013532 \n",
       "L 735.199593 109.757153 \n",
       "L 743.866255 111.401606 \n",
       "L 752.532916 112.946603 \n",
       "L 761.199578 114.392693 \n",
       "L 769.86624 115.741181 \n",
       "L 778.532902 116.994047 \n",
       "L 787.199564 118.153858 \n",
       "L 795.866225 119.223681 \n",
       "L 804.532887 120.207003 \n",
       "L 813.199549 121.107649 \n",
       "L 821.866211 121.929703 \n",
       "L 830.532873 122.677439 \n",
       "L 839.199535 123.35525 \n",
       "L 847.866196 123.967592 \n",
       "L 856.532858 124.518926 \n",
       "L 865.19952 125.01367 \n",
       "\" clip-path=\"url(#p3b8271919c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_13\">\n",
       "    <g id=\"patch_19\">\n",
       "     <path d=\"M 129.244889 38.307963 \n",
       "L 145.552702 38.307963 \n",
       "Q 148.552702 38.307963 148.552702 35.307963 \n",
       "L 148.552702 25.629838 \n",
       "Q 148.552702 22.629838 145.552702 22.629838 \n",
       "L 129.244889 22.629838 \n",
       "Q 126.244889 22.629838 126.244889 25.629838 \n",
       "L 126.244889 35.307963 \n",
       "Q 126.244889 38.307963 129.244889 38.307963 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- -2σ -->\n",
       "    <g transform=\"translate(129.244889 33.228276) scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"36.083984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3c3\" x=\"99.707031\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <g id=\"patch_20\">\n",
       "     <path d=\"M 294.51867 38.307963 \n",
       "L 304.463982 38.307963 \n",
       "Q 307.463982 38.307963 307.463982 35.307963 \n",
       "L 307.463982 25.629838 \n",
       "Q 307.463982 22.629838 304.463982 22.629838 \n",
       "L 294.51867 22.629838 \n",
       "Q 291.51867 22.629838 291.51867 25.629838 \n",
       "L 291.51867 35.307963 \n",
       "Q 291.51867 38.307963 294.51867 38.307963 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- -σ -->\n",
       "    <g transform=\"translate(294.51867 33.228276) scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#DejaVuSans-2d\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3c3\" x=\"36.083984\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <g id=\"patch_21\">\n",
       "     <path d=\"M 457.90495 38.307963 \n",
       "L 465.262763 38.307963 \n",
       "Q 468.262763 38.307963 468.262763 35.307963 \n",
       "L 468.262763 25.629838 \n",
       "Q 468.262763 22.629838 465.262763 22.629838 \n",
       "L 457.90495 22.629838 \n",
       "Q 454.90495 22.629838 454.90495 25.629838 \n",
       "L 454.90495 35.307963 \n",
       "Q 454.90495 38.307963 457.90495 38.307963 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- μ -->\n",
       "    <g transform=\"translate(457.90495 33.217338) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-Bold-3bc\" d=\"M 544 -1338 \n",
       "L 544 3500 \n",
       "L 1672 3500 \n",
       "L 1672 1466 \n",
       "Q 1672 1103 1828 926 \n",
       "Q 1984 750 2303 750 \n",
       "Q 2625 750 2781 926 \n",
       "Q 2938 1103 2938 1466 \n",
       "L 2938 3500 \n",
       "L 4063 3500 \n",
       "L 4063 1159 \n",
       "Q 4063 938 4114 850 \n",
       "Q 4166 763 4288 763 \n",
       "Q 4344 763 4395 778 \n",
       "Q 4447 794 4506 831 \n",
       "L 4506 50 \n",
       "Q 4341 -22 4195 -56 \n",
       "Q 4050 -91 3909 -91 \n",
       "Q 3631 -91 3454 26 \n",
       "Q 3278 144 3169 403 \n",
       "Q 3022 156 2811 32 \n",
       "Q 2600 -91 2322 -91 \n",
       "Q 2091 -91 1928 -17 \n",
       "Q 1766 56 1672 206 \n",
       "L 1672 -1338 \n",
       "L 544 -1338 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-Bold-3bc\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_16\">\n",
       "    <g id=\"patch_22\">\n",
       "     <path d=\"M 616.317793 38.307963 \n",
       "L 631.03498 38.307963 \n",
       "Q 634.03498 38.307963 634.03498 35.307963 \n",
       "L 634.03498 25.629838 \n",
       "Q 634.03498 22.629838 631.03498 22.629838 \n",
       "L 616.317793 22.629838 \n",
       "Q 613.317793 22.629838 613.317793 25.629838 \n",
       "L 613.317793 35.307963 \n",
       "Q 613.317793 38.307963 616.317793 38.307963 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- +σ -->\n",
       "    <g transform=\"translate(616.317793 33.228276) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-2b\" d=\"M 2944 4013 \n",
       "L 2944 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 2944 1741 \n",
       "L 2944 0 \n",
       "L 2419 0 \n",
       "L 2419 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "L 2419 2272 \n",
       "L 2419 4013 \n",
       "L 2944 4013 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-2b\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3c3\" x=\"83.789062\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <g id=\"patch_23\">\n",
       "     <path d=\"M 775.229073 38.307963 \n",
       "L 796.308761 38.307963 \n",
       "Q 799.308761 38.307963 799.308761 35.307963 \n",
       "L 799.308761 25.629838 \n",
       "Q 799.308761 22.629838 796.308761 22.629838 \n",
       "L 775.229073 22.629838 \n",
       "Q 772.229073 22.629838 772.229073 25.629838 \n",
       "L 772.229073 35.307963 \n",
       "Q 772.229073 38.307963 775.229073 38.307963 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "    </g>\n",
       "    <!-- +2σ -->\n",
       "    <g transform=\"translate(775.229073 33.228276) scale(0.1 -0.1)\">\n",
       "     <use xlink:href=\"#DejaVuSans-2b\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-3c3\" x=\"147.412109\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p3b8271919c\">\n",
       "   <rect x=\"7.2\" y=\"20.214138\" width=\"857.99952\" height=\"108.31401\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<lovely_tensors.repr_plt.PlotProxy at 0x7fe33efe7d60>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor cuda:0 4.080"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(res[0], torch.tensor(3).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.softmax(-1).chans(scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor[5, 13] i64 n=65 x∈[0, 74] μ=45.185 σ=25.633 cuda:0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(\n",
    "    model, model_params, ctx_len, encoded_prompt, n_tokens, temperature=0.0, top_k=1\n",
    "):\n",
    "    \"\"\"Generate n_tokens after prompt\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_tokens):\n",
    "            # print(encoded_prompt)\n",
    "            preds = model(\n",
    "                model_params, encoded_prompt[:, -ctx_len:], vocab_size=len(chars)\n",
    "            )\n",
    "            # print(f\"{preds=}\")\n",
    "\n",
    "            # probs = torch.nn.functional.softmax(preds, dim=-1)\n",
    "            # probs = probs.pow(1 / (temperature + 1e-6))\n",
    "\n",
    "            if temperature == 0.0:\n",
    "                next_token = torch.argmax(preds, dim=-1).unsqueeze(-1)\n",
    "            else:\n",
    "                log_probs = torch.nn.functional.log_softmax(preds, dim=-1)\n",
    "                # print(f\"{log_probs=}\")\n",
    "                log_probs = log_probs / (temperature + 1e-6)\n",
    "                probs = torch.exp(log_probs)\n",
    "                print(f\"{probs=}\")\n",
    "\n",
    "                # Implementing top-k sampling\n",
    "                top_k_probs, top_k_indices = torch.topk(probs, top_k)\n",
    "                next_token = torch.multinomial(top_k_probs, num_samples=1)\n",
    "                next_token = top_k_indices.gather(dim=1, index=next_token)\n",
    "\n",
    "            # print(f\"{next_token=}\")\n",
    "\n",
    "            encoded_prompt = torch.cat([encoded_prompt, next_token], dim=1)\n",
    "    return encoded_prompt\n",
    "\n",
    "\n",
    "generate(model, model_params, CTX_LEN, X[:5], 1, temperature=0.0, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the training data: 20,752,699\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the training data: {len(train_data):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xl0/work/projects/transformers/wandb/run-20231001_234209-70btl3n2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/llmnerds/my-awesome-project/runs/70btl3n2' target=\"_blank\">solar-capybara-172</a></strong> to <a href='https://wandb.ai/llmnerds/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/llmnerds/my-awesome-project' target=\"_blank\">https://wandb.ai/llmnerds/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/llmnerds/my-awesome-project/runs/70btl3n2' target=\"_blank\">https://wandb.ai/llmnerds/my-awesome-project/runs/70btl3n2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nd helped he'-> ' and n he he t t an and '\n",
      "'s little bro'-> 't the he te the and n t '\n",
      "'\\n\\nLily said,'-> '  t he te he he he he he'\n",
      "' fell off hi'-> ' tthe te the and n t  he'\n",
      "'me, there wa'-> 'n t  t he te he he he he'\n",
      "' was so happ'-> 'andandt an the tan the a'\n",
      "'a big, scary'-> ' wan the tan the and tan'\n",
      "'o play outsi'-> 'd the tan the and tan an'\n",
      "'he said to h'-> 'e tan and and tan the ta'\n",
      "'ttery. It wi'-> '\\nut the  to and and tan '\n",
      "\". You're a g\"-> 'e the the wand the the t'\n",
      "'ying with he'-> ' the and wand the the th'\n",
      "' see the big'-> 'e the the wand the the t'\n",
      "'eetie told t'-> 'he the the wand the the '\n",
      "'eat it, so h'-> 'e the the wand the the t'\n",
      "'o home and p'-> 'indang the the the the t'\n",
      "'e loved to p'-> 'ly and the the the the t'\n",
      "'ok nice.\"\\n\\nL'-> ' ly and the the the the '\n",
      "'y continued '-> 'the Lit the the the the '\n",
      "'s. The firew'-> ' he the the the the the '\n",
      "'k.\" The litt'-> 'ly wan to to tor to to t'\n",
      "'o anything b'-> 'e and a lit the to to\" t'\n",
      "'girl named L'-> 'ily wan a tou tore and a'\n",
      "'One day, Tim'-> 'my we a lit to tor to to'\n",
      "'ie.\\n\\n\"Hello,'-> ' to to to to the to to\" '\n",
      "\"ly didn't li\"-> 's and he want and and an'\n",
      "'wl and said,'-> ' \"I the want and and and'\n",
      "', he just wa'-> ' the want and and and an'\n",
      "' and family.'-> ' She want and and and an'\n",
      "'ed that they'-> ' was and the want and an'\n",
      "'n. \\n\\nTimmy s'-> 'he he the the the the th'\n",
      "'e on the law'-> ' the the the the the the'\n",
      "'mom mix the '-> 'the want and the the the'\n",
      "'e moon. But '-> 'the want and the the the'\n",
      "'py that he g'-> 'ound the the the the the'\n",
      "'immy was so '-> 'to the was toomm the the'\n",
      "'d a loud noi'-> 'ng the was and the the t'\n",
      "'sight of it.'-> ' She the was the was the'\n",
      "\"Oh no! I'm c\"-> 'ould the to to the was t'\n",
      "'day, Nemo sa'-> 'id, the was ate the the '\n",
      "'to sell his '-> 'and to to the the the th'\n",
      "'. Lily felt '-> 'lidnge the was and to th'\n",
      "'mommy and sa'-> 'id, the wan and to the w'\n",
      "'ey drove, th'-> 'e wan and to the wan and'\n",
      "'ops.\"\\n\\nLily '-> 'wan and to the wan and t'\n",
      "' tree. She p'-> 'as a the the the the the'\n",
      "'d a peach an'-> 'd the the the the the th'\n",
      "\" with Max's \"-> 'a to the the the the the'\n",
      "'. Can you fo'-> 'r the the the the the th'\n",
      "'herself. \\n\\nT'-> 'immy and the the the the'\n",
      "'ame and slap'-> 'ed to the the the the th'\n",
      "'things are b'-> 'e the the the the the th'\n",
      "'ed the strin'-> 'g to the the the the the'\n",
      "'eet you,\" Ja'-> 'd the the the the the th'\n",
      "'le girl name'-> 'd Lily was and to he the'\n",
      "'aid, \"That w'-> 'ant the was and the was '\n",
      "' said.\\n\\n\"I k'-> 'er the want the was and '\n",
      "\"me. Lily's m\"-> 'om the want the was and '\n",
      "'d to play wi'-> 'nt the was and the was a'\n",
      "'oy?\"\\n\\nLily s'-> 'he want the was and the '\n",
      "'e gave her t'-> 'he wand t the wand t the'\n",
      "', there was '-> 'a little wand t the wand'\n",
      "\"my's mom bro\"-> 'ure and t the wand t the'\n",
      "'ilthy! There'-> ' was a little wand t the'\n",
      "'agging tail.'-> ' Timmy up the wand t the'\n",
      "'y. Lily nodd'-> 'ed the the the want the '\n",
      "'in!\" Bob smi'-> 'd, the was a the was a t'\n",
      "'nd Lily was '-> 'and the was and the was '\n",
      "' proud of he'-> 'r the was a the was a th'\n",
      "'! Welcome to'-> ' the want the was and th'\n",
      "' felt sad an'-> 'd the was and the was an'\n",
      "'terwards, Ti'-> 'mmy was and the was and '\n",
      "'se it was he'-> 'r the was and the was an'\n",
      "'me pine nuts'-> 'idere was and the was an'\n",
      "' the envelop'-> 'le was and the was and t'\n",
      "' felt like d'-> 'ant the was and said, th'\n",
      "'hey asked hi'-> 's and the was and said, '\n",
      "'Once upon a '-> 'the was a the was a the '\n",
      "' but she cou'-> 'nd said, the was a the w'\n",
      "'le bird crie'-> 'nds and saw and the was '\n",
      "' loved to sw'-> 'as and said, the be was '\n",
      "'ving the mos'-> ' and to the be was the b'\n",
      "' a time, the'-> ' was and said, the be wa'\n",
      "'ter they fin'-> 'd said, to the but to th'\n",
      "'appy and pro'-> 'n a bear to the be was t'\n",
      "'egetables. H'-> 'e the becare was a the b'\n",
      "'ed Timmy. Ti'-> 'mmy was and the bear to '\n",
      "'loor and hur'-> 'e was a the becare was a'\n",
      "'\" \\n\\n\"No prob'-> 'le and s and the bear to'\n",
      "'ed to know w'-> 'as and the bear to her t'\n",
      "'promised nev'-> 'e was and the be was a t'\n",
      "'ough the cam'-> 'e want the be was a the '\n",
      "'ay, Timmy an'-> 'd the be was a the be wa'\n",
      "'ay, Max deci'-> 'de want the be was a the'\n",
      "'py to see hi'-> 'ttle be was and the be w'\n",
      "'ne day, her '-> 'to pla lit the be was a '\n",
      "'ery sad beca'-> 're was a lis and said th'\n",
      "'ack cat name'-> 'd the bear to play was a'\n",
      "'een before. '-> 'Timmy wan to ply was to '\n",
      "'eetie was so'-> ' pron a lit her the be w'\n",
      "' squirrel an'-> 'd the santing the said, '\n",
      "'e built a tr'-> 'e the said, the said, th'\n",
      "'utside to pl'-> 'an a the said, the said,'\n",
      "'o the store,'-> ' to he said, the said, t'\n",
      "'kyard. One d'-> 'ay want the santing the '\n",
      "'d that we ne'-> 'd the saw the said, th h'\n",
      "'e found a bi'-> 't th her the said, \"I th'\n",
      "'orange comb '-> 'the said, \"I th her the '\n",
      "'o happy and '-> 'said, \"I th her the said'\n",
      "'et. The lady'-> ' wan the said, \"I th her'\n",
      "'ough it out '-> 'the wan a becary, the wa'\n",
      "'shamed becau'-> 'se the wan the wan the w'\n",
      "'tle boy said'-> ', the wan the wan the wa'\n",
      "'m about the '-> 'was a becary, the way wa'\n",
      "'ll make your'-> 'e the wan the wan the wa'\n",
      "' count!\\n\\nAft'-> 'ed to the was and the wa'\n",
      "'lag. It belo'-> 'ved the was the was the '\n",
      "'r her bed. S'-> 'he want the was the was '\n",
      "'ains chuggin'-> '. She want the was the w'\n",
      "'e house. The'-> ' want the was the was th'\n",
      "'and told him'-> ' to he said, th he said,'\n",
      "'with lots of'-> ' to said, th he said, \"I'\n",
      "'nce upon a t'-> 'he said, \"I the said, \"I'\n",
      "'wait for you'-> ' the said, \"I the said, '\n",
      "'ost puppy. T'-> 'he said, \"I the said, \"I'\n",
      "'found a magi'-> 'zed the was a th her the'\n",
      "'ing us have '-> 'was a th her the was a t'\n",
      "' to lay in t'-> 'he was the was a th her '\n",
      "'\\nOnce upon a'-> ' the was a th her the wa'\n",
      "'ay on, Timmy'-> ' was and the was a th he'\n",
      "'owed Timmy t'-> 'he was a beat the was a '\n",
      "'a great time'-> ' was and the was a beat '\n",
      "'his tail. Th'-> 'e was a beat the was a b'\n",
      "'ll down. She'-> ' was a be was a beat the'\n",
      "'erywhere she'-> ' was a becaring an. Timm'\n",
      "'y felt sad b'-> 'e was a lit the was and '\n",
      "'\" he said. H'-> 'er the was a loved the w'\n",
      "'ly knew that'-> ' the was a loved the was'\n",
      "'n and throwi'-> 'ng the was a loved the w'\n",
      "'. \\n\\nTom lear'-> 'ned the was a loved the '\n",
      "'u for helpin'-> 'g to the was a liked to '\n",
      "'t trying new'-> ' the was a liked to her '\n",
      "' keep them s'-> 'aid, \"I condy was a love'\n",
      "'ery proud of'-> ' to her to her to her to'\n",
      "'m and placed'-> ' the was a liked to her '\n",
      "'ed to make m'-> 'om to the she she she sh'\n",
      "'ere was a la'-> 'y was a th her to her to'\n",
      "'ut after a w'-> 'an the she she she she s'\n",
      "'e, there was'-> ' a the she she she she s'\n",
      "'girl outside'-> ' and she she she she she'\n",
      "'f her choice'-> ' upon a loved to play wa'\n",
      "'nce and she '-> 'bear to play was a littl'\n",
      "'\"\\n\\nAs they w'-> 'as a loved to play was a'\n",
      "' She asked h'-> 'er to her to play was a '\n",
      "' The baby ha'-> 't to play was a little g'\n",
      "\"n't want to \"-> 'her to her to her to her'\n",
      "' They said, '-> '\"I wa the want the want '\n",
      "'y. Timmy gig'-> 'g to her to her to her t'\n",
      "'ok at the ni'-> 'g the was and the want t'\n",
      "' asleep.\\n\\nWh'-> 'e want the want the want'\n",
      "'p! You are s'-> 'aid, \"I wa lit to her to'\n",
      "'ad for accid'-> 'er to her to her to her '\n",
      "' to fix the '-> 'be the becaring said, \"I'\n",
      "' there was a'-> ' little to her to her to'\n",
      "'y helped her'-> ' to her to her to her to'\n",
      "'elry box. Sh'-> 'e want the want the want'\n",
      "'il and licke'-> 'd to her to her and and '\n",
      "'ly. She had '-> 'to her and and the want '\n",
      "'around all d'-> 'ery to her and and the w'\n",
      "'s instead. S'-> 'he want the want the wan'\n",
      "'he made a fa'-> 'ved to her to her to her'\n",
      "'apologized. '-> 'She said, th her to her '\n",
      "'old Timmy wh'-> 'er to her to her to her '\n",
      "'ess. She was'-> ' and the said, to her to'\n",
      "'while, but h'-> 'er to her to her to her '\n",
      "'ee it up clo'-> 'ved to the was a to the '\n",
      "\"camera's scr\"-> 'ethe was a to the was a '\n",
      "'park with hi'-> 's and to to the was a to'\n",
      "'rest. Lily w'-> 'as and to the was a to t'\n",
      "'worth it bec'-> 'are was a to the was a t'\n",
      "' the berries'-> 'tarted to ple was a lith'\n",
      "'the rain to '-> 'play was and the lithe l'\n",
      "', there was '-> 'a lithe lithe lithe lith'\n",
      "'om asked her'-> ' to ple was a lithe lith'\n",
      "\"ldn't wait t\"-> 'he lithe lithe lithe lit'\n",
      "'s like rocks'-> 'e her to the she said, \"'\n",
      "'I going to d'-> 'an and the she said, \"I '\n",
      "'th a few app'-> 'leatle gived to her to h'\n",
      "'r later. \"I '-> 'said, \"I said, \"I said, '\n",
      "' cat.\\n\\nMax r'-> 'ere was and the she said'\n",
      "'m got closer'-> ' the she said, \"I wa the'\n",
      "'\\nOnce upon a'-> ' the she said, \"I wa the'\n",
      "'ven small ac'-> 'e up the she said, \"I wa'\n",
      "'worm wriggli'-> 'en the she said, \"I wa t'\n",
      "'play with it'-> ' was a th her to her to '\n",
      "'m was right.'-> ' She wanted to her to he'\n",
      "' give up hop'-> 'ed to her to her to her '\n",
      "'b jumped out'-> ' the wanted to her to he'\n",
      "'en, the bird'-> ' the want the wanted to '\n",
      "'e, there was'-> ' a th her to her to her '\n",
      "'to remove it'-> ' was and the wanted to t'\n",
      "' color with '-> 'her to her to the wanted'\n",
      "' came to the'-> ' wanted to the wanted to'\n",
      "'rket to sell'-> ' named the wanted to the'\n",
      "'a big storm '-> 'the wanted to the wanted'\n",
      "'you have to '-> 'the said, ther to the sa'\n",
      "'ime, there w'-> 'as a little to the said,'\n",
      "'he playgroun'-> 'd the said, \"I lis and s'\n",
      "' Lily had a '-> 'little to the said, ther'\n",
      "'throat. Max '-> 'the said, \"I lis and sai'\n",
      "\"ut Timmy's m\"-> 'om the was a th her to p'\n",
      "\" day, Timmy'\"-> 's mom the was a th her t'\n",
      "'w a little d'-> 'ay, Lily was a th her to'\n",
      "'d that they '-> 'was a th her to play, th'\n",
      "'yed on the s'-> 'he was a th her to play,'\n",
      "'high up in t'-> 'he becare when to hed to'\n",
      "'lied. \\n\\nLily'-> ' was and her to her to h'\n",
      "' to share wh'-> ' a be and a becare when '\n",
      "'ed Timmy. Ti'-> 'mmy was and a becare whe'\n",
      "', as she was'-> ' a becare when to hed to'\n",
      "'n this hot d'-> 'ay was a the she saw the'\n",
      "'pped her pho'-> 'use and a time, there wa'\n",
      "'und a inchwo'-> 'n a time, there was a th'\n",
      "'o to bed now'-> 'n a time, there was a th'\n",
      "'e got some w'-> 'as a the she saw the she'\n",
      "'y,\" her mom '-> 'the bear the becamed and'\n",
      "'u. You know,'-> ' \"I wa beat was a bear t'\n",
      "' named Lily.'-> ' She becamed and a bear '\n",
      "'er decided t'-> 'he becamed and a bear th'\n",
      "'t to be safe'-> 'the becamed and a bear t'\n",
      "'m came in an'-> 'd saw the saw the saw th'\n",
      "' in a hole i'-> 't was and the said, \"I w'\n",
      "' to the stor'-> ' to the said, the said, '\n",
      "' for taking '-> 'and saw the saw the saw '\n",
      "'re sad and w'-> 'ant the saw the saw the '\n",
      "'me, there wa'-> 's and and and and and an'\n",
      "\"you'll write\"-> 'd to her to her to her t'\n",
      "' they realiz'-> 'ed and to her to her to '\n",
      "'She loved to'-> ' her to her to her to he'\n",
      "'rong and bra'-> 'nk and and to she saw to'\n",
      "'Timmy. Timmy'-> ' was and said, \"I was an'\n",
      "'got there, s'-> 'aid, \"I was and the said'\n",
      "' his friends'-> ' and said, \"I was and th'\n",
      "' a little bi'-> 'th her the said, \"I was '\n",
      "' she finishe'-> ' said, \"I was and the sa'\n",
      "'nk you for p'-> \"idn't the said, the said\"\n",
      "'nd how proud'-> ' and said, the said, the'\n",
      "'t there, the'-> 'r to the said, the said,'\n",
      "'e was a litt'-> 'le girl named the said, '\n",
      "' a gemstone.'-> ' She said, the said, the'\n",
      "'red, but her'-> ' to play was a time, the'\n",
      "'can use this'-> ' momethe started to ple '\n",
      "'d pour water'-> ' to play was a time, the'\n",
      "'s make some '-> 'and and a time, there wa'\n",
      "'ved spending'-> ' a time, there was a tim'\n",
      "'forgot all a'-> ' time, there was a time,'\n",
      "' dress-up an'-> 'd the start the she she '\n",
      "'ame over to '-> 'play wit the she she she'\n",
      "'nce upon a t'-> 'ime, there was a time, t'\n",
      "' time, there'-> ' was a time, there was a'\n",
      "'just what to'-> ' play was and the was an'\n",
      "'en, somethin'-> 'g there was and the was '\n",
      "'y to speak a'-> 'nd the was and the was a'\n",
      "' said, \"Yes,'-> ' Lily was and the was an'\n",
      "'knew that it'-> ' was and the was and the'\n",
      "'look what I '-> 'was and the so the so th'\n",
      "'iny truck. T'-> 'he said, \"I dan the so t'\n",
      "' friend Tomm'-> 'y was and a the so the s'\n",
      "' every weeke'-> 'ry and a the so the so t'\n",
      "'n poem!\"\\n\\nTi'-> 'mmy was and a the so the'\n",
      "'elicious ice'-> ' up and the she saw a be'\n",
      "'captain of t'-> 'he she saw a be and the '\n",
      "\"cut Teddy's \"-> 'a be and the she saw a b'\n",
      "'ced the wave'-> 'r the she saw a be and t'\n",
      "'red and didn'-> \"'t was a be and the she \"\n",
      "'he envelope '-> 'the so the so the so the'\n",
      "'owers too. \\n'-> '\\nThe so the said, to the'\n",
      "'it. \\n\\nTimmy '-> 'was and a time, there wa'\n",
      "'bitter and m'-> 'ome the so the so the so'\n",
      "'get up. Lily'-> ' was and the so the so t'\n",
      "'ful hands to'-> ' play with her to play w'\n",
      "'d their eyes'-> ' and said, \"I da time, t'\n",
      "'e monster wa'-> 's and to play with her t'\n",
      "'ited that sh'-> 'e said, \"I da time, ther'\n",
      "' little girl'-> ' named the so play with '\n",
      "'beans. She p'-> 'ay, said, \"I da the stak'\n",
      "'eating her o'-> 'n a time, there was a th'\n",
      "'ay with her '-> 'mom the stake a time, th'\n",
      "'t the scale '-> 'girde a time, there was '\n",
      "'d telling jo'-> 'y and she said, \"I da th'\n",
      "'surprised bu'-> 't the she said, \"I da li'\n",
      "' at the nice'-> ' up and said, \"I da litt'\n",
      "', she had to'-> ' the she said, \"I da lit'\n",
      "'nd. The frie'-> 'nds and said, \"I da litt'\n",
      "'hard to move'-> 'd to the she said, \"I da'\n",
      "'ent to a toy'-> ' and said, \"I want to he'\n",
      "'ittle boy na'-> 'med the she saw the she '\n",
      "'d job cleani'-> 'ng ther to her to her to'\n",
      "'on, the old '-> 'the she saw the she sad '\n",
      "'t me show yo'-> 'un and said, \"I want to '\n",
      "' was a littl'-> 'e girl to her and and a '\n",
      "'rstood. \"Oka'-> 'y was a th her and and a'\n",
      "' Timmy, came'-> ' and said, \"Whe said, \"W'\n",
      "'bad and real'-> 'ly with her and said, \"W'\n",
      "'he flower.\" '-> '\\n\\nLily was a th her and '\n",
      "'special powe'-> ' the she saw a little go'\n",
      "'ot nice and '-> 'a little go she said, th'\n",
      "'e boy named '-> 'and a little go she said'\n",
      "\"mmy's shiny \"-> 'was and a little go she '\n",
      "'Nemo got sic'-> 'k the she saw a little g'\n",
      "'ly said, \"He'-> ' she said, \"I wa the sta'\n",
      "'es. He also '-> 'her mom the started to h'\n",
      "'ime, there w'-> 'as a little girl named L'\n",
      "'\\n\\nBut then, '-> '\"I wa time, there was a '\n",
      "'was a little'-> ' girl named Lily with he'\n",
      "'atched as th'-> 'e was a little girl new '\n",
      "'have any new'-> ' the was a little girl n'\n",
      "'y, she decid'-> 'ed the was a little girl'\n",
      "'arned to be '-> 'and the was a little gir'\n",
      "'enerous and '-> 'said, the was and the wa'\n",
      "' them out so'-> ' her mom the was a littl'\n",
      "' to play wit'-> 'h her mom the was a litt'\n",
      "'ent to Timmy'-> ' was and said, \"I day wa'\n",
      "'t on his fin'-> 'd said, \"I day was a lit'\n",
      "', Max asked,'-> ' to play with her mom th'\n",
      "'es. From tha'-> 't to the be the be the b'\n",
      "'t wanted. On'-> 'e day, Lily with her toy'\n",
      "'pretty! Than'-> 'k the be the be the be t'\n",
      "'sky, enjoyin'-> 'g the be the be the be t'\n",
      "'e upon a tim'-> 'e, ther to the be the be'\n",
      "'m meant.\\n\\nOn'-> 'ce upon a little girl na'\n",
      "'ttle mouse n'-> 'ame and and and and and '\n",
      "'u so much, L'-> 'ily with her momed and s'\n",
      "'His mommy re'-> 're with her momed and sa'\n",
      "' outside, bu'-> 't her mommy and said, \"W'\n",
      "'eetie was ne'-> 'd the st the st the st t'\n",
      "'ng. Lily tol'-> 'd and said, \"I didn\\'t th'\n",
      "'d with his t'-> 'oy and said, \"I didn\\'t t'\n",
      "'un that Timm'-> 'y was and said, \"I didn\\''\n",
      "'als were exc'-> 'id to the st the st the '\n",
      "'ness was imp'-> 'orten and and and and an'\n",
      "' brushed his'-> ' mom the said, \"I da mom'\n",
      "' mommy gifte'-> 'r to play a little girl '\n",
      "'the heat of '-> 'her mom the said, \"I da '\n",
      "'sed to alway'-> 's asked to her mom the s'\n",
      "'ead.\" \\n\\nLily'-> ' was a th her to the sta'\n",
      "' show his mo'-> 'm the started to her to '\n",
      "'ly and his d'-> 'ay was a th her to the s'\n",
      "'o his owner.'-> ' The so to her to the st'\n",
      "'uck the worm'-> ' the started to her to t'\n",
      "'ppy to know '-> 'a time, the was a th he '\n",
      "'l kept stopp'-> 'ed to he was a th he was'\n",
      "'rite mug. On'-> 'e day, Lily with to he w'\n",
      "'ardrobe with'-> ' the was a th he was a t'\n",
      "' where he li'-> 'ttle girl named the was '\n",
      "'on a time, t'-> 'her the saw the stalk a '\n",
      "'und. She pic'-> 'ked her the started to h'\n",
      "'he burned hi'-> 's the started to her the'\n",
      "'to put some '-> 'the started to her the s'\n",
      "'r the cookie'-> 'nds a the started to her'\n",
      "'d Lily. She '-> 'shed to her to her to he'\n",
      "' lots of bea'-> 'r to her to her to her t'\n",
      "'shop to see '-> 'was and to her to her to'\n",
      "'d traded the'-> ' she she she she she she'\n",
      "'grow big and'-> ' to her to her to her to'\n",
      "'many adventu'-> 're with her the stande a'\n",
      "'d saw her fr'-> 'iends and said, \"I was a'\n",
      "' work and fo'-> 'r the stande and the sta'\n",
      "'ce of pie. I'-> 't was and the stande and'\n",
      "' asked if sh'-> 'e saw and the stande and'\n",
      "' he squeezed'-> ' and the was a the was a'\n",
      "'hey continue'-> 'd here was a the was and'\n",
      "\"d.\\n\\nTimmy's \"-> 'a the was and the was a '\n",
      "'ig puddle.\\n\\n'-> 'Once upon a time, there '\n",
      "'too fast and'-> ' the was a the was and t'\n",
      "' on it.\\n\\nLil'-> 'y was a the started to h'\n",
      "' at the park'-> ' a time, ther more was a'\n",
      "', the bee fo'-> 'r and said, \"I wa the st'\n",
      "'rl named Lil'-> 'y was a the started to h'\n",
      "'upon a time,'-> ' ther more was a the sta'\n",
      "'. Timmy love'-> ' her mom the so her mom '\n",
      "'se party for'-> ' a little girl named and'\n",
      "'the freezer '-> 'and said, \"I was a littl'\n",
      "'wner made su'-> 're with her mom the so h'\n",
      "' again.\\n\\nOnc'-> 'e upon a little girl nam'\n",
      "'she had neve'-> 'd to the saw the sad the'\n",
      "'n, Lily neve'-> 'd to the saw the sad the'\n",
      "'a ball and s'-> 'he saw the sad the saw t'\n",
      "'looked at it'-> ' the saw the sad the saw'\n",
      "'with his fri'-> 'ends. The so her the saw'\n",
      "' little girl'-> ' new as mom the saw the '\n",
      "'of peaches a'-> 'nd said the saw the said'\n",
      "' operator wa'-> 'ys and her mom the saw t'\n",
      "\"t it's not r\"-> 'an the saw the said the '\n",
      "'It smelled s'-> 'aid the saw the said the'\n",
      "'issing colla'-> 't to play was a big to p'\n",
      "' that someti'-> 'me, ther to play was a b'\n",
      "'e bird. \"Why'-> ' was a big to play was a'\n",
      "'ted to decor'-> 'e was a big to play was '\n",
      "' be better n'-> 'amed the sto play was a '\n",
      "' and colder.'-> ' Timmy was a big and sai'\n",
      "'Hello, littl'-> 'e girl named and said, \"'\n",
      "'ied, \"Yes, i'-> 'mpon a the started to he'\n",
      "'ound. In fac'-> 'k the started to her mom'\n",
      "' playing wit'-> 'h her mom the started to'\n",
      "', I need a p'-> 'retter to the started to'\n",
      "'rom that day'-> ' was a little girl ned t'\n",
      "'g to help so'-> ' her mom the started to '\n",
      "'ay, Whiskers'-> ' a little girl ned the s'\n",
      "' track of ou'-> 'tside and said, \"I was a'\n",
      "'to jump in. '-> 'They was a big and said,'\n",
      "' me, Bob. Yo'-> 'uld the was a big and sa'\n",
      "' a toy. She '-> 'was a big and said, \"The'\n",
      "'was able to '-> 'play with hat to her and'\n",
      "', but it was'-> ' a big and said, \"The wa'\n",
      "'hat?\" She sa'-> 'id, \"When to the stiled '\n",
      "' a cup that '-> 'to the stiled the st the'\n",
      "'wn and picke'-> 'd the stiled the st the '\n",
      "' next day, t'-> 'he stiled the st the sai'\n",
      "'Lily. She lo'-> 'ved to the stiled the st'\n",
      "'sors and sho'-> 'ught her mom the was a l'\n",
      "'.\\n\\nWhile the'-> ' was a little girl named'\n",
      "'nd he wanted'-> ' to play with her mom th'\n",
      "'to play. \\n\\nT'-> 'immy was a little girl n'\n",
      "'ew game.\"\\n\\nT'-> 'immy was a little girl n'\n",
      "'s very sad.\\n'-> '\\nOnce upon a the sto the'\n",
      "'him and saw '-> 'the sto the sto the sto '\n",
      "'w a big, sca'-> 're was a little girl nam'\n",
      "'dentally kno'-> 'w the sto the sto the st'\n",
      "'e fun making'-> ' ther to to the sto the '\n",
      "'hant. He was'-> ' a little girl named the'\n",
      "'ily said. \"W'-> 'hen to the was and sad t'\n",
      "'ed to play w'-> 'ith here was a little gi'\n",
      "'en she saw h'-> 'ere was a little girl na'\n",
      "'o really fas'-> ' a little girl named the'\n",
      "' meant.\\n\\nOnc'-> 'e upon a that she be and'\n",
      "' time, there'-> ' was a big and said the '\n",
      "'t in his hou'-> \"ldn't was a big and said\"\n",
      "' cut and it '-> 'was and her and said the'\n",
      "\"t's hard to \"-> 'her and said the be and '\n",
      "'e, there was'-> ' a big and saw and the s'\n",
      "' Lily. \"I wi'-> 'shed mom the sto the st '\n",
      "'y good at it'-> ' the st the st the st th'\n",
      "\"e day, Max's\"-> ' a big and saw and the s'\n",
      "' back with a'-> ' big and saw and the st '\n",
      "'ily. She lov'-> 'ed to the started to the'\n",
      "'er dollhouse'-> 'e it was and sade the st'\n",
      "'\\n\\nOnce upon '-> 'a the started to the sta'\n",
      "'napkin to cl'-> 'earned the started to th'\n",
      "'with them ag'-> 'ain. Timmy was a little '\n",
      "'her piece of'-> ' the started to her momm'\n",
      "'l. She said,'-> ' \"I was and said, \"I was'\n",
      "'ed it up and'-> ' said, \"I was and said, '\n",
      "'ayed togethe'-> 'r mommy was a little gir'\n",
      "'upon a time,'-> ' ther mommy was a little'\n",
      "' shore inste'-> ' the started to stanter '\n",
      "'e wanted to '-> 'stanter to stanter to st'\n",
      "'realized tha'-> 't to stanter to stanter '\n",
      "'re fruits an'-> 'd said, \"I was and said,'\n",
      "'to her wardr'-> 'ent day with her mom the'\n",
      "'d, \"I told y'-> 'ould the little bear and'\n",
      "'py by going '-> 'and said, \"I wa be and s'\n",
      "'go on an adv'-> 'ery and to he little bea'\n",
      "'s and run fa'-> 'ven and to play and saw '\n",
      "'put them tog'-> 'er to her and said, \"I w'\n",
      "'w the pit to'-> ' the was a big the was a'\n",
      "'med Lily. Sh'-> 'e was the was the was th'\n",
      "'was impresse'-> ' a big the was a big the'\n",
      "'hat day on, '-> 'the was a big the was a '\n",
      "'play catch a'-> 'nd said, \"Whad a big the'\n",
      "' Timmy said.'-> ' She said, \"I want to st'\n",
      "'what her mom'-> ' the st was a little gir'\n",
      "'some other c'-> 'ou said, \"I want to stan'\n",
      "'g race they '-> 'were was a little girl n'\n",
      "'n your bike '-> 'to stant she said, \"I wa'\n",
      "'rying to mak'-> 'e and said, \"I want the '\n",
      "' weather.\\n\\nO'-> 'nce upon a little girl n'\n",
      "'ted to look '-> 'and said, \"I want the st'\n",
      "'nked the man'-> 'y was a little girl name'\n",
      "'n a time, th'-> 'er mommy was a little gi'\n",
      "' asked him t'-> 'o play with her and said'\n",
      "'ce upon a ti'-> 'me, ther and said, \"I wa'\n",
      "'car in her o'-> 'n a time, ther and said,'\n",
      "\"'m caught in\"-> ' the start to play with '\n",
      "'Wow, Lily! Y'-> 'ould the start to play w'\n",
      "'yons and mar'-> 'ked to the started to th'\n",
      "'un away but '-> 'the started to the start'\n",
      "'e hole and u'-> 'p and said, \"I didn\\'t wa'\n",
      "'t was a big '-> 'ther and said, \"I didn\\'t'\n",
      "'mom saw her '-> 'and said, \"I didn\\'t was '\n",
      "'d her dad. \\n'-> '\\nTimmy was a little girl'\n",
      "'d?\"\\n\\nDucky r'-> 'er and said, \"I wal a li'\n",
      "' a little bo'-> \"uldn't was a little girl\"\n",
      "'omething mor'-> 'e was a little girl name'\n",
      "'ike the miss'-> ' and said, \"I wal a litt'\n",
      "'sounds of th'-> 'e so her momether mometh'\n",
      "' home. The g'-> 'rout the so her momether'\n",
      "' glass of wa'-> 's a big and said, \"I wan'\n",
      "'toy. She tol'-> 'd the so her momether mo'\n",
      "', she put on'-> ' a big and said, \"I want'\n",
      "' for a reaso'-> ' happy was a little girl'\n",
      "'d it up and '-> 'said, \"I wa the sto the '\n",
      "'y! She ran a'-> ' little girl named the s'\n",
      "' Mommy said,'-> ' \"I wa the sto the sto t'\n",
      "'oke up, she '-> 'said, \"I wa the sto the '\n",
      "' fish and th'-> 'e she said, to the she s'\n",
      "'to play outs'-> 'ide and to the she said,'\n",
      "' twig on the'-> ' she said, to the she sa'\n",
      "'y find his w'-> 'as a little girl named t'\n",
      "' ticket to D'-> \"on't and to the she said\"\n",
      "'gry. She dec'-> 'itearoue she saw a big a'\n",
      "' all about t'-> 'he so play with her mom '\n",
      "'a with her m'-> 'om the so play with her '\n",
      "'re was a pre'-> 'tted to play with her mo'\n",
      "'seahorse was'-> ' a big and said, \"Thapke'\n",
      "'e was a litt'-> 'le girl named the so sai'\n",
      "'ould cut him'-> ' to the so said, \"I wa t'\n",
      "'loved to pla'-> 'y with her mommy and sai'\n",
      "' \"Mommy, can'-> ' and said, \"I wa time, t'\n",
      "\"ax's owner d\"-> 'ide and said, \"I wa time'\n",
      "'g unexpected'-> ' to her mom the was a bi'\n",
      "' in the gard'-> 'enlizza be a big ther mo'\n",
      "'named Timmy.'-> ' She was a big ther mome'\n",
      "'at she asked'-> ' to her mom the was a bi'\n",
      "'e was happy '-> 'was a big ther mome the '\n",
      "\"Lily didn't \"-> 'was and to the started t'\n",
      "'Once upon a '-> 'time, there was a little'\n",
      "'yed on the s'-> 'tarted to the started to'\n",
      "' pour some j'-> 'ust was a little girl na'\n",
      "'was too sour'-> 'y and to the started to '\n",
      "'to play with'-> ' her mom the little girl'\n",
      "' thanked Lil'-> 'y the little girl named '\n",
      "' saw it.\\n\\nOn'-> 'ce upon a time, there wa'\n",
      "' a toy that '-> 'day, Lily and her mom th'\n",
      "' adventures '-> 'and they was a little gi'\n",
      "'nd choose ou'-> 't the was a little girl '\n",
      "'her towel, b'-> 'ecared to hed mome the w'\n",
      "'fly, \"What h'-> 'er mom the was a little '\n",
      "'very noisy o'-> 'n a time, there was a li'\n",
      "'he had to wa'-> 'y was a little girl name'\n",
      "' that there '-> 'was a little girl named '\n",
      "'y felt sad a'-> 'nd they were with her an'\n",
      "'the tree.\\n\\nA'-> 's a little girl named Li'\n",
      "'as very angr'-> 'andmander to play with h'\n",
      "' nice and he'-> 'r and they were with her'\n",
      "'ke money for'-> ' he was a little girl na'\n",
      "'r small you '-> 'can the was a little gir'\n",
      "' upon a time'-> ', there was a little gir'\n",
      "\"mmy didn't w\"-> 'as and she was a little '\n",
      "' a little mo'-> 'm the was a little girl '\n",
      "'med Lily. Sh'-> 'e was a big the was and '\n",
      "'Max. \"I\\'m go'-> 'mmy and said, \"Thapked t'\n",
      "'my was happy'-> ' was a big the was and s'\n",
      "'then on, Lil'-> 'y and sa back the was a '\n",
      "'weak and she'-> ' was a big the was and s'\n",
      "'icked up the'-> ' started the started the'\n",
      "', \"Mommy, ca'-> 'n a lithere was and sad '\n",
      "'ily asked he'-> 'r mom the started the st'\n",
      "'rtoon charac'-> 'e upon a time, the start'\n",
      "'ho loved to '-> 'play with her mom the st'\n",
      "' breathe in '-> 'the said the said ay was'\n",
      "'both very ha'-> 'tted and the said ay was'\n",
      "'mmy gave her'-> ' and the said ay was and'\n",
      "' help them g'-> 'ot his the said ay was a'\n",
      "'icked the be'-> 'r the said ay was and th'\n",
      "'One day, the'-> ' was a ly was a ly was a'\n",
      "'arlie.\\n\\n\"Hel'-> ' the was a ly was a ly w'\n",
      "'dolls and sa'-> 'id, \"I was and said, \"I '\n",
      "'ey were surp'-> 'or a time, there was a l'\n",
      "'n the sun. O'-> 'ne day, Lily her to happ'\n",
      "'. You saved '-> 'to happy and started to '\n",
      "'. The cat an'-> 'd started to her the sai'\n",
      "\"m's friend, \"-> 'the said, \"I was and sta'\n",
      "' the sun. Bu'-> 't the said, \"I was and s'\n",
      "'sked.\\n\\n\"Of c'-> 'arke the said, \"I was an'\n",
      "'time, there '-> 'was a ly was a ly the wa'\n",
      "'ddy, and the'-> ' was a ly was a ly the w'\n",
      "'a different '-> 'her to her to her to her'\n",
      "'nt and said,'-> ' \"I was and said, \"I was'\n",
      "'d the butter'-> ' to her to her to her to'\n",
      "' loud noise.'-> ' The was a be and she wa'\n",
      "'nd sweep the'-> ' was a be and she was an'\n",
      "'ed, \"What sh'-> 'e was a be and she was a'\n",
      "'utside with '-> \"her to plin't the was a \"\n",
      "'ost she had '-> \"to plin't the was a be a\"\n",
      "' She asked L'-> 'ily was and said, \"I wat'\n",
      "'her and live'-> 'd to her to her to her t'\n",
      "'omplete. \\n\\nS'-> 'he saw a big there was a'\n",
      "'The end.\\n\\nOn'-> 'ce upon a time, there wa'\n",
      "' all about t'-> 'he saw a big there was a'\n",
      "'Daddy, look '-> 'a the said, \"I was and s'\n",
      "'h it. \\n\\nLily'-> ' was and sad a big there'\n",
      "'ng in the su'-> 're was a big there was a'\n",
      "'d to swim in'-> ' the said, \"I was and sa'\n",
      "' mom. \"Mom, '-> 'th her to the said, \"I w'\n",
      "'oar through '-> 'asked and he was a loved'\n",
      "'was surprise'-> 'd to play with he was an'\n",
      "'he sat there'-> 'r and he was a loved to '\n",
      "'are you doin'-> 'g and he was a loved to '\n",
      "'isneyland! L'-> 'ily was and her and he w'\n",
      "'enly, he hea'-> 'r to play with to play w'\n",
      "'lped her esc'-> 'ause he was a love the w'\n",
      "' him behind '-> 'said, \"I was a little gi'\n",
      "'rom them and'-> ' said, \"I was a little g'\n",
      "'ised but the'-> ' was a love the was a lo'\n",
      "'h. Timmy did'-> 'ny was a little girl nam'\n",
      "'e dog named '-> 'the said, \"I was a littl'\n",
      "' and told he'-> 'r the said, \"I was a lit'\n",
      "'ght and prom'-> ' the said, \"I was a litt'\n",
      "'a new dress '-> 'and said, \"I was a littl'\n",
      "'resting than'-> 'k said, \"I was a little '\n",
      "'he garden.\\n\\n'-> 'Once upon a time, there '\n",
      "'in a zigzag '-> 'there was a little girl '\n",
      "'\\n\\nOnce upon '-> 'a time, there was a litt'\n",
      "' was a littl'-> 'e girl named Lily was an'\n",
      "'ing in the m'-> 'om the said, \"I way was '\n",
      "'ng the coal '-> 'not the said, \"I way was'\n",
      "'y. She loved'-> ' to her to her to her to'\n",
      "'gging along '-> 'there was a big there wa'\n",
      "'e and fell a'-> 'nd said, \"I way was a bi'\n",
      "' into pieces'-> 's and her to her to her '\n",
      "'d them, but '-> 'the was a little girl na'\n",
      "' in the sky.'-> ' She was a little girl n'\n",
      "'e stage. One'-> ' day, Lily was and her t'\n",
      "'rying and Li'-> 'ly was and her to her to'\n",
      "'shine. One d'-> 'ay, \"I wa lit\\'s mad a li'\n",
      "' The end.\\n\\nO'-> 'nce upon a timed Lily wa'\n",
      "' a terrible '-> \"got the was a lit's mad \"\n",
      "\" of Lily's h\"-> \"er to the was a lit's ma\"\n",
      "'ed that shar'-> \"ten to the was a lit's m\"\n",
      "'ad fun, but '-> 'the said, \"I with her an'\n",
      "'more. He cur'-> 'e with her and said, \"I '\n",
      "'en they arri'-> 'ends a big there was a b'\n",
      "'r grandma ma'-> 'lly with her and said, \"'\n",
      "'usual creatu'-> 're was a big there was a'\n",
      "'y were all h'-> 'e saw a ly wide the saw '\n",
      "'r and restor'-> ' a ly and said, \"I way w'\n",
      "\"move. Timmy'\"-> 's a ly wide the saw a ly'\n",
      "'cted happene'-> 'd. She saw a ly wide the'\n",
      "'ing turns pi'-> 'ck the saw a ly wide the'\n",
      "'dcastles and'-> ' to the said, \"I was a b'\n",
      "'dy bear and '-> 'to the said, \"I was a be'\n",
      "'to find that'-> ' to there was a because '\n",
      "' It made her'-> ' to there was a because '\n",
      "'t has my fav'-> 'e him to there was a bec'\n",
      "'it all up ag'-> 'ain the was and and and '\n",
      "'licopter sho'-> 'went to the wan and and '\n",
      "'because it m'-> 'ould her to the wan and '\n",
      "'p sailed awa'-> 'sked to the way was a li'\n",
      "'beak. \"Here '-> 'was a little girl named '\n",
      "'e picked the'-> ' wan and and and the way'\n",
      "'sitting on a'-> ' little girl named Lily.'\n",
      "' had to be a'-> ' little girl named Lily.'\n",
      "' girl named '-> 'Lily. She was a little g'\n",
      "', \"The weigh'-> 't was and and and the wa'\n",
      "'it was fun a'-> 'nd said, \"I with her to '\n",
      "'or with his '-> 'mom the wan a little gir'\n",
      "'a time, ther'-> 'e was a little girl name'\n",
      "' all the lov'-> 'ed to play with her to p'\n",
      "'rawl around '-> 'the with her to play wit'\n",
      "'res with her'-> ' mom the she she she she'\n",
      "'a little gir'-> 'l named Lily was a littl'\n",
      "'le on her fa'-> 'milear the she she she s'\n",
      "' a while, Li'-> 'll named Lily was a litt'\n",
      "'rt her. The '-> 'she she she she she she '\n",
      "'w and paint.'-> ' Timmy was a little girl'\n",
      "'y was able t'-> 'he saw a little girl nam'\n",
      "'licopters. F'-> 'rom the saw a little gir'\n",
      "' proud of he'-> 'r and said, \"I with her '\n",
      "'oved snow so'-> ' happy with her and said'\n",
      "'\\nOnce upon a'-> ' time, there was a littl'\n",
      "'to sing and '-> 'the way, the was and a b'\n",
      "'ect things l'-> 'ittle girl named Lily wa'\n",
      "'t had been w'-> 'as a little girl named L'\n",
      "' sometimes, '-> 'big there was a little g'\n",
      "'xploring und'-> 'er to he saw a big there'\n",
      "\"dn't underst\"-> 'al ay was a big there wa'\n",
      "'ommy, can yo'-> 'u wanted to he saw a big'\n",
      "'Timmy accide'-> 'd to her to he saw a big'\n",
      "' cookies tog'-> 'ethere was a big there w'\n",
      "'ng things ca'-> 'red the said, \"I with he'\n",
      "'pple looks d'-> \"idn't was a little girl \"\n",
      "'e. The owner'-> ' the said, \"I with her m'\n",
      "'a clean room'-> ' the said, \"I with her m'\n",
      "'and said, \"Y'-> 'ou for the said, \"I with'\n",
      "'he forest. O'-> 'ne day, Lily was a littl'\n",
      "\"y didn't kno\"-> 'the way was a little gir'\n",
      "'azed and ask'-> 'e the way was a little g'\n",
      "'I have an id'-> 'e a little girl named Li'\n",
      "'e backyard.\\n'-> '\\nOnce upon a time, there'\n",
      "'s a little g'-> 'irl named Lily was a big'\n",
      "\"didn't like \"-> 'the she she she she she '\n",
      "'ept the floo'-> 'k the she she she she sh'\n",
      "'named Lily. '-> 'She she she she she she '\n",
      "'ay at the pa'-> 'rk the she she she she s'\n",
      "'t do you wan'-> 'ted and the way was a li'\n",
      "'mall prince '-> 'up and the way was a lit'\n",
      "'y, Whiskers '-> 'and the way was a little'\n",
      "'ething else.'-> ' Timmy was a little girl'\n",
      "'ground to hi'-> 's friends a little girl '\n",
      "' day on, Mit'-> 'tle girl named Lily was '\n",
      "'is help. Fro'-> 'm the wanted to the want'\n",
      "'y become cle'-> 'd and the wanted to the '\n",
      "'\\n\\nAnd from t'-> 'he was a little girl nam'\n",
      "' you least e'-> 'n the wanted to the want'\n",
      "\"Lily's mom t\"-> 'he saw the saw the saw t'\n",
      "'lpless, and '-> 'the saw the saw the saw '\n",
      "'s. He also l'-> 'ived to the saw the saw '\n",
      "' silly toy m'-> 'ontiled and the saw the '\n",
      "'of cheese. T'-> 'he saw the saw the saw t'\n",
      "'other and wa'-> 's a lit the looked the l'\n",
      "'t it was too'-> 'ked the looked the looke'\n",
      "'.\\n\\nOnce upon'-> ' a time, there was a lit'\n",
      "'oyed the coo'-> 'ked the looked the looke'\n",
      "'ly how to us'-> 'e her there was a lit th'\n",
      "'e!\\n\\nOnce upo'-> 'n a time, ther mome the '\n",
      "'told her to '-> 'her mome the stare was a'\n",
      "'y gave her a'-> 'nd the stare was a littl'\n",
      "' and sing a '-> 'little girl named Lily w'\n",
      "'mean.\\n\\nOnce '-> 'upon a time, ther mome t'\n",
      "'ily was so h'-> 'at day was a beck the wa'\n",
      "' Benny! The '-> 'went the was a beck the '\n",
      "'. \\n\\nHer momm'-> 'y and the was a beck the'\n",
      "'ded to make '-> 'the was a beck the was a'\n",
      "'d, \"Sometime'-> ' to her and the was a be'\n",
      "'d when he ne'-> 'w and to play was and to'\n",
      "'ed the cows?'-> '\" \\n\\nLily was and to play'\n",
      "'ed sorting, '-> 'but the saw and to play '\n",
      "'ways remembe'-> ' and to play was and to '\n",
      "'ter and put '-> 'to play was and to play '\n",
      "' was excited'-> ' to play of the she saw '\n",
      "'d alarm. It '-> 'was a little girl named '\n",
      "'rld. He woul'-> 'd her to play of the she'\n",
      "'lived happil'-> 'y to play of the she saw'\n",
      "'d no. Lily w'-> 'as a little girl named L'\n",
      "'portant to s'-> 'he saw and to the store '\n",
      "'sure to have'-> ' and to the store was an'\n",
      "'other rocks '-> 'to the store was and to '\n",
      "'ome,\" said M'-> 'ax wan and to the store '\n",
      "'or his next '-> 'was and to the store was'\n",
      "'ed to rain. '-> 'The she said, \"I wa time'\n",
      "'warn his fri'-> 'ends a little girl named'\n",
      "'thought abou'-> 't a little girl named Li'\n",
      "'autiful mess'-> ' a little girl named Lil'\n",
      "'ined that it'-> ' was a little girl named'\n",
      "'outside, esp'-> 'ed to the way was and th'\n",
      "'kept crawlin'-> 'gly with her mommy and t'\n",
      "' doing thing'-> ' ther the wan and the wa'\n",
      "'n floating i'-> 't the wan and the wan an'\n",
      "'ove, they sa'-> 'w and the wan and the wa'\n",
      "' ignorant. T'-> 'he wa time, ther to play'\n",
      "'x was so hap'-> 'py to play with her to p'\n",
      "'ve. They rac'-> 'k to play with her to pl'\n",
      "'saw her frie'-> 'nds a big the wa time, t'\n",
      "' remembered '-> 'to play with her to play'\n",
      "'e day, her m'-> 'om the said, \"I wanted t'\n",
      "'y day. One n'-> 'amed the said, \"I wanted'\n",
      "'n the park w'-> 'ent to here wanted to he'\n",
      "'e tried to m'-> 'ake ay went to here want'\n",
      "'puddle that '-> 'day was and said, \"I wan'\n",
      "'side and loo'-> 'ked the so hat to her to'\n",
      "'el running t'-> 'her to her to her to her'\n",
      "'s carrot.\\n\\nB'-> 'ut the so hat to her to '\n",
      "'ound. He pic'-> 'ked and said, \"I wa be a'\n",
      "'t to trade i'-> 't a little girl named Li'\n",
      "'high?\" Tweet'-> ' to play was a little gi'\n",
      "'d it in her '-> 'mom the saw a little gir'\n",
      "'s request.\\n\\n'-> 'Once upon a time, ther t'\n",
      "' make a spli'-> 'e the saw a little girl '\n",
      "' and knocked'-> ' and said, \"I with her m'\n",
      "'upon a time,'-> ' ther mom the saw and sa'\n",
      "'s played qui'-> 'cked to the saw the saw '\n",
      "'tle girl saw'-> ' and said, \"I with her m'\n",
      "'h her favori'-> 'ng to the saw the saw an'\n",
      "'ull it out, '-> 'the saw and said, \"I wit'\n",
      "'coin that sp'-> 'ened the somethen the so'\n",
      "'er and start'-> 'ed the somethen the some'\n",
      "'y pieces. Li'-> 'ly was a little girl nam'\n",
      "'a time, ther'-> 'e was a little girl name'\n",
      "'nce upon a t'-> 'he somethen the somethen'\n",
      "'ater and sta'-> 'rted to the sad to the s'\n",
      "' realized sh'-> 'e said, \"I wa to the sad'\n",
      "'ng! Lily and'-> ' said, \"I wa to the sad '\n",
      "' time, there'-> ' was a little girl named'\n",
      "'hy are you s'-> 'he said, \"I wa to the sa'\n",
      "'spaghetti wi'-> 'th her mom the said, \"I '\n",
      "\"wasn't scare\"-> 'ful and the said, \"I wa '\n",
      "' on, Lily wo'-> 'uld her mom the said, \"I'\n",
      "'ying on the '-> 'said, \"I wa time, ther t'\n",
      "'ontinued to '-> 'play out the said, \"I wa'\n",
      "'crown?\" The '-> 'she some the some the so'\n",
      "'wanted to he'-> 'r mom the some the some '\n",
      "'e judge was '-> 'a little girl named Lily'\n",
      "'om said, \"No'-> ', ther the some the some'\n",
      "'the farmer a'-> 'nd said, \"I wa time, the'\n",
      "'d it became '-> 'the was a big ther and s'\n",
      "\"dn't want to\"-> ' the was a big ther and '\n",
      "'iends played'-> ' to the way of the was a'\n",
      "'realized tha'-> 't day on a big ther and '\n",
      "' tried to re'-> 'rfly and said, \"I was a '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_23856/2780676932.py\", line 60, in <module>\n",
      "    X, y = get_batch(train_data, ctx_len=CTX_LEN, batch_size=BATCH_SIZE, shuffle=True)\n",
      "  File \"/tmp/ipykernel_23856/3277373966.py\", line 19, in get_batch\n",
      "    batch = [get_random_item(data, ctx_len) for _ in range(batch_size)]\n",
      "  File \"/tmp/ipykernel_23856/3277373966.py\", line 19, in <listcomp>\n",
      "    batch = [get_random_item(data, ctx_len) for _ in range(batch_size)]\n",
      "  File \"/tmp/ipykernel_23856/3277373966.py\", line 10, in get_random_item\n",
      "    return torch.tensor(encode(src)), torch.tensor(encode(dst))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>loss</td><td>1.34596</td></tr><tr><td>val_loss</td><td>1.36791</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-capybara-172</strong> at: <a href='https://wandb.ai/llmnerds/my-awesome-project/runs/70btl3n2' target=\"_blank\">https://wandb.ai/llmnerds/my-awesome-project/runs/70btl3n2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231001_234209-70btl3n2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m run:\n\u001b[1;32m     59\u001b[0m     \u001b[39mwhile\u001b[39;00m token_count \u001b[39m<\u001b[39m TRAIN_TOKENS:\n\u001b[0;32m---> 60\u001b[0m         X, y \u001b[39m=\u001b[39m get_batch(train_data, ctx_len\u001b[39m=\u001b[39;49mCTX_LEN, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     61\u001b[0m         X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     62\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[52], line 19\u001b[0m, in \u001b[0;36mget_batch\u001b[0;34m(data, ctx_len, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_batch\u001b[39m(data, ctx_len, batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yields a tuple of tensors of shape (batch_size, ctx).\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    X, shape=B C\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    y, shape=B C\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     batch \u001b[39m=\u001b[39m [get_random_item(data, ctx_len) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size)]\n\u001b[1;32m     20\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(X), torch\u001b[39m.\u001b[39mstack(y)\n",
      "Cell \u001b[0;32mIn[52], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_batch\u001b[39m(data, ctx_len, batch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Yields a tuple of tensors of shape (batch_size, ctx).\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m    X, shape=B C\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    y, shape=B C\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     batch \u001b[39m=\u001b[39m [get_random_item(data, ctx_len) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size)]\n\u001b[1;32m     20\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m     22\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(X), torch\u001b[39m.\u001b[39mstack(y)\n",
      "Cell \u001b[0;32mIn[52], line 10\u001b[0m, in \u001b[0;36mget_random_item\u001b[0;34m(data, ctx)\u001b[0m\n\u001b[1;32m      7\u001b[0m src \u001b[39m=\u001b[39m data[i : i \u001b[39m+\u001b[39m ctx]\n\u001b[1;32m      8\u001b[0m dst \u001b[39m=\u001b[39m data[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m : i \u001b[39m+\u001b[39m ctx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m---> 10\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(encode(src)), torch\u001b[39m.\u001b[39;49mtensor(encode(dst))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CTX_LEN = 12\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4096\n",
    "LR = 0.1\n",
    "\n",
    "TRAIN_TOKENS = 1_000_000_000\n",
    "\n",
    "\n",
    "LOG_INTERVAL = min(\n",
    "    (min(TRAIN_TOKENS, len(train_data)) // (BATCH_SIZE * CTX_LEN) // 10) + 1, 1000\n",
    ")\n",
    "VALIDATION_INTERVAL = LOG_INTERVAL * 2\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "    entity=\"llmnerds\",\n",
    "    config={\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"ctx\": CTX_LEN,\n",
    "    },\n",
    ")\n",
    "\n",
    "model_params = make_params(EMBEDDING_DIM, CTX_LEN, len(chars), 2, device)\n",
    "init_params(model_params)\n",
    "\n",
    "\n",
    "def get_params(param_dict_or_list_or_tensor) -> list[torch.Tensor]:\n",
    "    params = []\n",
    "    if isinstance(param_dict_or_list_or_tensor, dict):\n",
    "        for v in param_dict_or_list_or_tensor.values():\n",
    "            params.extend(get_params(v))\n",
    "    elif isinstance(param_dict_or_list_or_tensor, list):\n",
    "        for v in param_dict_or_list_or_tensor:\n",
    "            params.extend(get_params(v))\n",
    "    else:  # If it's a tensor\n",
    "        params.append(param_dict_or_list_or_tensor)\n",
    "    return params\n",
    "\n",
    "\n",
    "param_list = get_params(model_params)\n",
    "\n",
    "for p in param_list:\n",
    "    p.requires_grad = True\n",
    "\n",
    "optim = torch.optim.Adam(param_list, lr=1e-3)\n",
    "\n",
    "i = 1\n",
    "total_loss = 0\n",
    "val_total_loss = 0\n",
    "token_count = 0\n",
    "\n",
    "\n",
    "# batch_gen = get_batch(train_data, ctx_len=CTX_LEN, batch_size=BATCH_SIZE, shuffle=True)\n",
    "with run:\n",
    "    while token_count < TRAIN_TOKENS:\n",
    "        X, y = get_batch(train_data, ctx_len=CTX_LEN, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        token_count = i * BATCH_SIZE * CTX_LEN\n",
    "\n",
    "        preds = model(params=model_params, input_ids=X, vocab_size=len(chars))\n",
    "        loss = torch.nn.functional.cross_entropy(input=preds, target=y[:, -1])\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # for param in model_params.values():\n",
    "            #     param -= LR * param.grad\n",
    "            #     param.grad.zero_()\n",
    "\n",
    "        if i % LOG_INTERVAL == 0:\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"loss\": total_loss / LOG_INTERVAL,\n",
    "                    \"epoch\": token_count // len(train_data),\n",
    "                },\n",
    "                step=token_count,\n",
    "            )\n",
    "            total_loss = 0\n",
    "\n",
    "        if i % VALIDATION_INTERVAL == 0:\n",
    "            j = 0\n",
    "            for X_val, y_val in get_epoch(\n",
    "                val_data, ctx_len=CTX_LEN, batch_size=4096, shuffle=False\n",
    "            ):\n",
    "                X_val = X_val.to(device)\n",
    "                y_val = y_val.to(device)\n",
    "                with torch.no_grad():\n",
    "                    preds = model(\n",
    "                        params=model_params, input_ids=X_val, vocab_size=len(chars)\n",
    "                    )\n",
    "                    loss = torch.nn.functional.cross_entropy(preds, y_val[:, -1])\n",
    "                    val_total_loss += loss.item()\n",
    "                    j += 1\n",
    "            wandb.log({\"val_loss\": val_total_loss / j}, step=token_count, commit=True)\n",
    "\n",
    "            prompts = get_batch(val_data, ctx_len=CTX_LEN, batch_size=5)[0].to(device)\n",
    "            generated = generate(\n",
    "                model=model,\n",
    "                model_params=model_params,\n",
    "                encoded_prompt=prompts,\n",
    "                ctx_len=CTX_LEN,\n",
    "                n_tokens=CTX_LEN * 2,\n",
    "            )\n",
    "            for p in generated:\n",
    "                char_list = p.tolist()\n",
    "                pre_prompt = char_list[:CTX_LEN]\n",
    "                post_prompt = char_list[CTX_LEN:]\n",
    "\n",
    "                print(f\"{repr(decode(pre_prompt))}-> {repr(decode(post_prompt))}\")\n",
    "\n",
    "            val_total_loss = 0\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<lovely_tensors.repr_chans.ChanProxy at 0x7fe38841eec0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params[\"pos_enc\"].div(4).chans(scale=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = get_batch(val_data, ctx_len=CTX_LEN, batch_size=5)[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'er! \\nThe nex'-> \"t day, Mian's mommy was excited the juice. They always. One day, who had a special bying. They had lottle joge again. The smy loved the boy came. After to the hole around again.\\nOnce upon a time, heavy, Timmy saw tight. A fincy only the world and lishes. She knew it to all her longerded to open the \"\n",
      "'yons and sta'-> 'y of a happy\\'s toys asked toys to their can. From that day on, every dog! The cat was very sad. Her mom said, happy tow excited for a wards selfush an inside to be needet. Lily went to help other look promise toy cursy for is.\\nOne day, she would little crreful, \"We ble crying. They saw that the pine'\n",
      "'hing unexpec'-> 'ted. It is tho lottle boy. He was excited to see wear appined to see Pally learn and went to the pandow. This yag cats. She glapped her laughed. She wolded Sue. Sue said, \"No, so not having to marccold not started Tom and his differents the speeper- and they all their stickets and them a pudding on '\n",
      "'ded to keep '-> 'behieset and nover again. \\nMr. Sue\\'s help you fighting on to stoodly. Hey created to man they fox them commore saw the moft powner.\\n\"He\\'s mom came over to play anytor in the farthat they letter. Suddenly, a bird night buffel them rest of the big the backyard.\\nOnce upon a time, in the decided to play'\n",
      "'ned the last'-> \"effinishes.\\nThey lived the sun appily with his friends chair now ball. The little fire the mar. They throken for sweech. Let's sittle any gone. \\nAnd so, their car best, it was dark to daye, the fead if he way. Spot went to the patch on the grounds again. One day, he found a beautiful for yountil, bu\"\n"
     ]
    }
   ],
   "source": [
    "generated = generate(\n",
    "    model=model,\n",
    "    model_params=model_params,\n",
    "    encoded_prompt=prompts,\n",
    "    ctx_len=CTX_LEN,\n",
    "    n_tokens=300,\n",
    "    temperature=1,\n",
    "    top_k=50,\n",
    ")\n",
    "for p in generated:\n",
    "    char_list = p.tolist()\n",
    "    pre_prompt = char_list[:CTX_LEN]\n",
    "    post_prompt = char_list[CTX_LEN:]\n",
    "\n",
    "    print(f\"{repr(decode(pre_prompt))}-> {repr(decode(post_prompt))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "d = json.load(open(\"tmp/data00.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(u) -> list[torch.Tensor]:  # u: param_dict_or_list_or_tensor\n",
    "    flatten = lambda x: [item for sublist in x for item in sublist]\n",
    "    return (\n",
    "        flatten(u.values())\n",
    "        if isinstance(u, dict)\n",
    "        else flatten(u)\n",
    "        if isinstance(u, list)\n",
    "        else [u]\n",
    "    )\n",
    "\n",
    "\n",
    "param_list = get_params(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor[128] x∈[-2.123, 2.940] μ=-0.047 σ=1.024 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.712, 2.628] μ=-0.039 σ=1.006 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.249, 2.290] μ=-0.032 σ=0.969 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.941, 2.137] μ=-0.017 σ=0.951 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.924, 3.264] μ=0.044 σ=1.083 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.790, 1.974] μ=0.044 σ=1.073 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.425, 2.174] μ=0.008 σ=0.819 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.192, 2.293] μ=0.026 σ=0.961 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.331, 3.046] μ=0.056 σ=0.947 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.999, 2.812] μ=-0.030 σ=1.109 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.824, 2.423] μ=-0.045 σ=0.981 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.368, 2.735] μ=-0.104 σ=0.840 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.499, 2.802] μ=0.011 σ=1.023 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.988, 2.761] μ=-0.065 σ=1.063 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.727, 3.332] μ=0.022 σ=1.143 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.324, 3.429] μ=-0.086 σ=1.053 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.810, 2.289] μ=-0.041 σ=1.019 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.134, 3.014] μ=0.097 σ=0.932 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.613, 2.951] μ=-0.085 σ=1.069 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.023, 2.318] μ=-0.058 σ=1.004 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.367, 2.360] μ=-0.055 σ=0.942 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.607, 2.714] μ=-0.069 σ=0.965 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.594, 2.407] μ=0.098 σ=0.991 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.190, 2.321] μ=0.095 σ=1.018 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-1.956, 2.589] μ=0.148 σ=1.068 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.508, 3.449] μ=-0.024 σ=1.032 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.513, 2.761] μ=0.058 σ=0.979 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.714, 2.319] μ=-0.049 σ=1.082 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.860, 2.714] μ=-0.073 σ=1.051 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.245, 2.544] μ=-0.020 σ=1.036 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.595, 2.756] μ=-0.001 σ=1.047 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.732, 3.247] μ=-0.116 σ=1.064 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.252, 2.356] μ=-0.023 σ=0.955 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.605, 3.073] μ=0.002 σ=0.992 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.661, 2.351] μ=-0.053 σ=1.012 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.163, 1.745] μ=-0.025 σ=0.854 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.343, 2.640] μ=0.056 σ=1.056 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.320, 2.310] μ=-0.006 σ=0.966 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.864, 2.752] μ=0.064 σ=1.029 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.375, 2.566] μ=-0.007 σ=0.953 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.786, 2.280] μ=-0.006 σ=1.000 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.101, 2.652] μ=0.034 σ=0.976 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.788, 2.073] μ=-0.076 σ=0.934 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.054, 3.113] μ=0.074 σ=1.082 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.209, 2.406] μ=0.125 σ=0.983 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.037, 2.707] μ=0.084 σ=1.116 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-1.675, 2.107] μ=0.063 σ=0.803 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.007, 3.287] μ=0.137 σ=1.031 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.057, 3.092] μ=-0.066 σ=0.988 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.080, 2.733] μ=-0.108 σ=1.033 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.793, 2.344] μ=0.049 σ=1.040 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.645, 2.611] μ=0.004 σ=0.968 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.814, 2.281] μ=-0.070 σ=0.983 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.097, 1.750] μ=-0.039 σ=0.870 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.101, 2.316] μ=-0.042 σ=0.978 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.174, 2.939] μ=0.120 σ=1.021 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.635, 3.204] μ=-0.042 σ=0.968 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.793, 1.943] μ=0.029 σ=0.944 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.354, 2.119] μ=0.080 σ=0.880 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.139, 2.922] μ=0.084 σ=0.998 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.976, 2.313] μ=-0.004 σ=1.169 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.899, 2.305] μ=-0.091 σ=1.013 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.551, 2.178] μ=0.006 σ=0.924 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-3.542, 2.605] μ=0.257 σ=1.039 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.196, 3.318] μ=0.118 σ=1.058 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.635, 2.547] μ=0.075 σ=0.919 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.351, 3.001] μ=-0.020 σ=1.000 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.413, 2.628] μ=0.074 σ=0.998 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.399, 2.072] μ=0.017 σ=0.912 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.580, 2.119] μ=-0.077 σ=1.006 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.634, 2.485] μ=-0.003 σ=0.944 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.557, 2.676] μ=0.003 σ=0.974 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.288, 2.583] μ=0.017 σ=0.946 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.919, 2.442] μ=-0.110 σ=1.099 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.352, 2.042] μ=-0.013 σ=0.955 grad UnbindBackward0 cuda:0,\n",
       " tensor[128] x∈[-2.574, 2.187] μ=0.009 σ=1.007 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.094, 1.485] μ=0.037 σ=0.780 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.416, 1.421] μ=-0.068 σ=1.028 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.798, 2.054] μ=0.494 σ=0.877 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.935, 1.831] μ=0.273 σ=1.262 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.477, 1.107] μ=-0.050 σ=0.760 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.690, 2.137] μ=0.325 σ=1.561 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.084, 2.577] μ=0.252 σ=1.375 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.510, 1.153] μ=-0.050 σ=0.987 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.322, 1.276] μ=0.110 σ=0.741 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.115, 1.571] μ=0.188 σ=0.709 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.216, 2.421] μ=-0.524 σ=1.361 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.600, 2.117] μ=0.377 σ=0.975 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.384, 1.850] μ=-0.271 σ=1.314 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.595, 1.752] μ=0.224 σ=0.910 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.531, 0.791] μ=-0.671 σ=0.898 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.177, 1.332] μ=-0.031 σ=0.792 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.171, 2.830] μ=0.108 σ=1.110 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.209, 2.399] μ=0.532 σ=1.007 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.115, 1.952] μ=0.276 σ=0.935 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.620, 0.999] μ=-0.142 σ=0.932 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.524, 1.620] μ=-0.062 σ=0.826 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.466, 1.898] μ=0.188 σ=1.157 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.432, 2.021] μ=-0.130 σ=0.930 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.744, 1.610] μ=-0.181 σ=1.151 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.219, 1.801] μ=0.205 σ=1.071 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.470, 1.525] μ=-0.120 σ=0.891 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.194, 1.802] μ=0.068 σ=1.355 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.354, 1.933] μ=-0.055 σ=0.918 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.908, 1.144] μ=-0.226 σ=1.171 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.146, 1.232] μ=-0.176 σ=0.761 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.498, 1.733] μ=-0.261 σ=0.991 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.807, 2.256] μ=-0.120 σ=1.090 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.901, 1.354] μ=-0.531 σ=0.914 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.419, 2.759] μ=0.403 σ=1.286 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.811, 2.136] μ=0.247 σ=1.059 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.801, 2.699] μ=-0.049 σ=1.604 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.657, 0.956] μ=-0.412 σ=0.854 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.187, 1.880] μ=-0.070 σ=0.927 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.033, 1.395] μ=-0.435 σ=1.042 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.114, 2.467] μ=0.470 σ=1.102 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.498, 1.221] μ=-0.064 σ=0.851 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.492, 2.171] μ=0.484 σ=1.275 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.294, 1.336] μ=-0.151 σ=0.868 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.205, 2.077] μ=-0.283 σ=1.025 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.447, 2.161] μ=0.429 σ=1.388 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.251, 2.467] μ=0.111 σ=0.980 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.267, 2.052] μ=0.291 σ=0.963 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.678, 1.918] μ=0.000 σ=1.034 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.591, 2.501] μ=0.436 σ=1.136 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.095, 1.572] μ=-0.164 σ=1.272 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.527, 1.883] μ=0.357 σ=0.705 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.401, 0.785] μ=-0.461 σ=1.032 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.100, 1.578] μ=-0.030 σ=1.160 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.698, 1.803] μ=0.149 σ=1.201 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.887, 1.386] μ=-0.195 σ=0.896 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.452, 1.089] μ=0.007 σ=1.111 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.419, 2.677] μ=0.461 σ=1.155 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.320, 1.573] μ=-0.054 σ=0.895 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.286, 2.052] μ=0.328 σ=0.983 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.079, 1.219] μ=-0.092 σ=0.564 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.665, 1.190] μ=0.079 σ=0.821 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.797, 1.597] μ=-0.666 σ=1.032 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.443, 3.037] μ=0.476 σ=1.185 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.286, 2.142] μ=0.017 σ=0.893 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.280, 1.168] μ=0.061 σ=0.755 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.055, 1.100] μ=-0.089 σ=1.066 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.709, 2.909] μ=0.494 σ=1.252 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.331, 2.487] μ=0.209 σ=1.138 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.475, 2.525] μ=-0.066 σ=1.220 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.196, 1.473] μ=0.190 σ=0.866 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.071, 1.328] μ=0.287 σ=0.811 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.113, 1.309] μ=0.158 σ=1.001 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.410, 1.348] μ=0.183 σ=0.810 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.126, 1.802] μ=0.093 σ=0.938 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.420, 1.797] μ=0.423 σ=1.082 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.477, 2.897] μ=1.018 σ=1.104 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.121, 1.643] μ=0.465 σ=0.878 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.870, 1.718] μ=-0.314 σ=1.060 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.338, 1.832] μ=0.506 σ=1.188 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.265, 0.957] μ=-0.116 σ=0.662 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.023, 2.609] μ=0.134 σ=0.968 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.974, 1.230] μ=-0.422 σ=0.994 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.806, 1.464] μ=-0.147 σ=0.928 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.459, 1.605] μ=-0.219 σ=0.980 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.262, 2.401] μ=0.334 σ=1.062 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.792, 1.147] μ=-0.167 σ=0.931 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.263, 1.672] μ=0.361 σ=0.863 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.546, 2.222] μ=0.434 σ=1.153 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.975, 1.846] μ=0.166 σ=1.192 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.099, 2.560] μ=0.341 σ=1.085 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.884, 2.199] μ=-0.154 σ=1.131 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.256, 1.384] μ=-0.034 σ=0.851 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.686, 2.711] μ=0.284 σ=0.936 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.346, 1.658] μ=0.193 σ=0.989 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.927, 0.706] μ=-0.370 σ=0.879 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.019, 0.693] μ=-0.569 σ=0.781 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.178, 2.246] μ=-0.154 σ=1.439 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.922, 1.672] μ=-0.077 σ=0.955 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.135, 1.131] μ=-0.486 σ=1.054 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.507, 1.053] μ=0.042 σ=0.853 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.429, 2.227] μ=0.124 σ=1.074 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.210, 1.988] μ=-0.020 σ=1.226 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.798, 0.968] μ=0.050 σ=0.460 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.582, 2.695] μ=0.428 σ=0.880 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.193, 2.219] μ=0.341 σ=1.012 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.466, 1.737] μ=0.268 σ=0.942 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.900, 1.421] μ=0.036 σ=0.995 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.360, 1.081] μ=-0.070 σ=0.721 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.755, 1.624] μ=-0.289 σ=0.960 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.878, 1.985] μ=0.370 σ=1.523 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.268, 1.143] μ=-0.015 σ=0.775 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-2.890, 1.866] μ=-0.256 σ=1.214 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.177, 1.655] μ=-0.030 σ=0.991 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.392, 2.324] μ=0.114 σ=1.057 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.756, 1.982] μ=0.470 σ=0.777 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.105, 2.373] μ=0.013 σ=1.132 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.786, 0.964] μ=-0.360 σ=0.825 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.742, 2.020] μ=0.212 σ=1.024 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.313, 1.935] μ=0.287 σ=0.994 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.105, 1.883] μ=0.072 σ=1.006 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.048, 3.304] μ=0.274 σ=1.142 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.303, 1.187] μ=0.300 σ=0.745 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.996, 1.695] μ=-0.181 σ=1.091 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.632, 1.644] μ=0.045 σ=1.024 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.395, 1.431] μ=0.103 σ=0.866 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.413, 1.256] μ=0.477 σ=0.518 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-1.233, 1.289] μ=-0.315 σ=0.678 grad UnbindBackward0 cuda:0,\n",
       " tensor[12] x∈[-0.662, 1.567] μ=0.401 σ=0.684 grad UnbindBackward0 cuda:0,\n",
       " {'w_ln1': tensor[128] x∈[0.998, 1.002] μ=1.000 σ=0.002 grad cuda:0,\n",
       "  'b_ln1': tensor[128] \u001b[38;2;127;127;127mall_zeros\u001b[0m grad cuda:0,\n",
       "  'w_attn_k': tensor[128, 128] n=16384 (64Kb) x∈[-4.283, 3.451] μ=-0.001 σ=1.000 grad cuda:0,\n",
       "  'w_attn_q': tensor[128, 128] n=16384 (64Kb) x∈[-3.940, 3.747] μ=0.005 σ=0.999 grad cuda:0,\n",
       "  'w_attn_v': tensor[128, 128] n=16384 (64Kb) x∈[-4.517, 3.907] μ=-0.002 σ=1.000 grad cuda:0,\n",
       "  'w_fc_up': tensor[512, 128] n=65536 (0.2Mb) x∈[-4.203, 4.062] μ=-0.003 σ=1.000 grad cuda:0,\n",
       "  'b_fc_up': tensor[512] 2Kb x∈[-2.629, 3.337] μ=-0.035 σ=0.965 grad cuda:0,\n",
       "  'w_fc_down': tensor[128, 512] n=65536 (0.2Mb) x∈[-4.135, 4.489] μ=0.006 σ=0.999 grad cuda:0,\n",
       "  'b_fc_down': tensor[128] x∈[-2.344, 3.346] μ=-0.029 σ=0.996 grad cuda:0,\n",
       "  'w_ln2': tensor[128] x∈[0.998, 1.002] μ=1.000 σ=0.002 grad cuda:0,\n",
       "  'b_ln2': tensor[128] x∈[-0.002, 0.002] μ=1.616e-05 σ=0.002 grad cuda:0},\n",
       " {'w_ln1': tensor[128] x∈[0.998, 1.002] μ=1.000 σ=0.002 grad cuda:0,\n",
       "  'b_ln1': tensor[128] \u001b[38;2;127;127;127mall_zeros\u001b[0m grad cuda:0,\n",
       "  'w_attn_k': tensor[128, 128] n=16384 (64Kb) x∈[-3.616, 3.644] μ=-0.008 σ=1.000 grad cuda:0,\n",
       "  'w_attn_q': tensor[128, 128] n=16384 (64Kb) x∈[-3.874, 3.787] μ=-0.003 σ=0.991 grad cuda:0,\n",
       "  'w_attn_v': tensor[128, 128] n=16384 (64Kb) x∈[-3.887, 4.047] μ=-0.005 σ=0.997 grad cuda:0,\n",
       "  'w_fc_up': tensor[512, 128] n=65536 (0.2Mb) x∈[-4.360, 4.108] μ=-0.004 σ=0.997 grad cuda:0,\n",
       "  'b_fc_up': tensor[512] 2Kb x∈[-3.378, 2.665] μ=0.003 σ=0.995 grad cuda:0,\n",
       "  'w_fc_down': tensor[128, 512] n=65536 (0.2Mb) x∈[-4.597, 3.931] μ=-0.000 σ=0.999 grad cuda:0,\n",
       "  'b_fc_down': tensor[128] x∈[-3.319, 2.947] μ=0.057 σ=0.910 grad cuda:0,\n",
       "  'w_ln2': tensor[128] x∈[0.998, 1.002] μ=1.000 σ=0.002 grad cuda:0,\n",
       "  'b_ln2': tensor[128] x∈[-0.002, 0.002] μ=-0.000 σ=0.002 grad cuda:0},\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.999,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.000,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.999,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.000,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.001,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.999,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.999,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 1.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 0.998,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.000,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.000,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.000,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.001,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 -0.002,\n",
       " tensor grad UnbindBackward0 cuda:0 0.002]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
